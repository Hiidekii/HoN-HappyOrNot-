{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9db5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import face_recognition as fr\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('gui_2/assets/haarcascade_frontalface_default.xml')\n",
    "HEIGHT, WIDTH =48,48\n",
    "other_emotions =  [ 'fear', 'anger', 'disgust', 'neutral']\n",
    "initial_emotions = ['sadness','happiness', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3c360950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(x,initial):\n",
    "    if initial:\n",
    "        if x in initial_emotions:\n",
    "            return x\n",
    "        else:\n",
    "            return \"other\"\n",
    "    else: \n",
    "        if x in other_emotions:\n",
    "            return x\n",
    "        else:\n",
    "            return \"other\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6a9ac7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/all/train/\",\"data/all/test/\"]#[\"data/CK_cut/\"]# #[\"data/CK+/\",\"data/fer/train/\"]\n",
    "# data  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs = []\n",
    "state = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735199f0",
   "metadata": {},
   "source": [
    "## Datos para entrenar emociones iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "355c9697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise\n",
      "disgust\n",
      "anger\n",
      "neutral\n",
      "happiness\n",
      "fear\n",
      "sadness\n",
      "surprise\n",
      "disgust\n",
      "anger\n",
      "neutral\n",
      "happiness\n",
      "fear\n",
      "sadness\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        print(item)\n",
    "        if item not in ignore:\n",
    "            imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "            \n",
    "            if item in initial_emotions:\n",
    "                state.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "            else:\n",
    "                state.extend([\"other\" for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10c87b",
   "metadata": {},
   "source": [
    "## Datos para entrenar resto emociones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "367dfb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise\n",
      "disgust\n",
      "anger\n",
      "neutral\n",
      "happiness\n",
      "fear\n",
      "sadness\n",
      "surprise\n",
      "disgust\n",
      "anger\n",
      "neutral\n",
      "happiness\n",
      "fear\n",
      "sadness\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        print(item)\n",
    "        if item not in ignore:\n",
    "            if item in other_emotions:\n",
    "                imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "                state.extend([item for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1a6c9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25230, {'anger', 'disgust', 'fear', 'neutral'})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs),set(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fae39",
   "metadata": {},
   "source": [
    "## *********************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "75e892e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = []\n",
    "try:\n",
    "    imgs_ = []\n",
    "    for p in imgs:\n",
    "        temp = Image.open(p)\n",
    "        save = temp.copy()\n",
    "        imgs_.append(save)\n",
    "        temp.close()\n",
    "except:\n",
    "    errs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "54a50273",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = []\n",
    "HEIGHT, WIDTH =48,48\n",
    "for f in imgs_:\n",
    "    img = f.convert(\"L\").resize((HEIGHT, WIDTH))\n",
    "    imgs_array.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bdd1a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = [el/255 for el in imgs_array]\n",
    "imgs_array = np.array(imgs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "79f7f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array= imgs_array.reshape((len(imgs_array),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "207647b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25230, 48, 48, 1)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b8bfe",
   "metadata": {},
   "source": [
    "## Con este modo de cargar imagenes, filtramos caras con cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ad0c14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs = []\n",
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": get_emotion(item,True)}for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "32166a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ = []\n",
    "state = []\n",
    "for p in imgs:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.1, 5) #1.1 factor scale, cuanto  disminuye imagen entre pasos\n",
    "                                                        #5 MIN nEIGHBORS cuantos vecinos cada posible \n",
    "                                                        # rectangulo considerar para prediccion\n",
    "                                                        # (valor minimo px de la cara detectada)\n",
    "                                                        # (valor maximo px)\n",
    "            \n",
    "    if len(faces)==1:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_.append(recortada)\n",
    "            state.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_ = [el/255 for el in imgs_]\n",
    "imgs_array = np.array(imgs_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cbcb58bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22087, 48, 48)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a61537e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array= imgs_array.reshape((len(imgs_array),48,48,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b221d9",
   "metadata": {},
   "source": [
    "# Preparamos entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b65e3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(state)\n",
    "y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f5764951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_anger</th>\n",
       "      <th>0_disgust</th>\n",
       "      <th>0_fear</th>\n",
       "      <th>0_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25227</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25228</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25229</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25230 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0_anger  0_disgust  0_fear  0_neutral\n",
       "0            0          1       0          0\n",
       "1            0          1       0          0\n",
       "2            0          1       0          0\n",
       "3            0          1       0          0\n",
       "4            0          1       0          0\n",
       "...        ...        ...     ...        ...\n",
       "25225        0          0       1          0\n",
       "25226        0          0       1          0\n",
       "25227        0          0       1          0\n",
       "25228        0          0       1          0\n",
       "25229        0          0       1          0\n",
       "\n",
       "[25230 rows x 4 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "335e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array,y_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2b5d459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,BatchNormalization,Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD, Adamax\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9db01d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "751fe068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 1-conv\n",
    "model.add(Conv2D(64,(3,3),padding='same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2-conv\n",
    "model.add(Conv2D(128,(5,5),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ed763968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "533/533 [==============================] - 109s 204ms/step - loss: 1.1036 - accuracy: 0.5551 - val_loss: 2.0242 - val_accuracy: 0.5404\n",
      "Epoch 2/5000\n",
      "533/533 [==============================] - 7s 13ms/step - loss: 0.9560 - accuracy: 0.6021 - val_loss: 0.9616 - val_accuracy: 0.5938\n",
      "Epoch 3/5000\n",
      "533/533 [==============================] - 7s 13ms/step - loss: 0.8719 - accuracy: 0.6353 - val_loss: 0.8950 - val_accuracy: 0.6350\n",
      "Epoch 4/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.8118 - accuracy: 0.6684 - val_loss: 1.1639 - val_accuracy: 0.5906\n",
      "Epoch 5/5000\n",
      "533/533 [==============================] - 8s 15ms/step - loss: 0.7720 - accuracy: 0.6861 - val_loss: 0.9937 - val_accuracy: 0.6403\n",
      "Epoch 6/5000\n",
      "533/533 [==============================] - 7s 13ms/step - loss: 0.7302 - accuracy: 0.7017 - val_loss: 1.1243 - val_accuracy: 0.5061\n",
      "Epoch 7/5000\n",
      "533/533 [==============================] - 6s 12ms/step - loss: 0.7026 - accuracy: 0.7161 - val_loss: 0.8581 - val_accuracy: 0.6318\n",
      "Epoch 8/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.6700 - accuracy: 0.7322 - val_loss: 0.9856 - val_accuracy: 0.5747\n",
      "Epoch 9/5000\n",
      "533/533 [==============================] - 7s 12ms/step - loss: 0.6333 - accuracy: 0.7470 - val_loss: 1.0503 - val_accuracy: 0.6667\n",
      "Epoch 10/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.6032 - accuracy: 0.7587 - val_loss: 0.8983 - val_accuracy: 0.6471\n",
      "Epoch 11/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.5816 - accuracy: 0.7664 - val_loss: 0.7463 - val_accuracy: 0.6820\n",
      "Epoch 12/5000\n",
      "533/533 [==============================] - 6s 12ms/step - loss: 0.5472 - accuracy: 0.7875 - val_loss: 0.8034 - val_accuracy: 0.6799\n",
      "Epoch 13/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.5141 - accuracy: 0.7959 - val_loss: 0.7170 - val_accuracy: 0.7079\n",
      "Epoch 14/5000\n",
      "533/533 [==============================] - 6s 12ms/step - loss: 0.4855 - accuracy: 0.8121 - val_loss: 0.7069 - val_accuracy: 0.7353\n",
      "Epoch 15/5000\n",
      "533/533 [==============================] - 7s 13ms/step - loss: 0.4555 - accuracy: 0.8225 - val_loss: 0.9114 - val_accuracy: 0.6249\n",
      "Epoch 16/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.4146 - accuracy: 0.8386 - val_loss: 0.9701 - val_accuracy: 0.6413\n",
      "Epoch 17/5000\n",
      "533/533 [==============================] - 6s 12ms/step - loss: 0.4017 - accuracy: 0.8471 - val_loss: 0.7957 - val_accuracy: 0.7058\n",
      "Epoch 18/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.3598 - accuracy: 0.8624 - val_loss: 0.9260 - val_accuracy: 0.6223\n",
      "Epoch 19/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.3511 - accuracy: 0.8677 - val_loss: 0.8270 - val_accuracy: 0.7301\n",
      "Epoch 20/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.3139 - accuracy: 0.8802 - val_loss: 0.8169 - val_accuracy: 0.6862\n",
      "Epoch 21/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.2991 - accuracy: 0.8882 - val_loss: 1.1605 - val_accuracy: 0.7142\n",
      "Epoch 22/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.2815 - accuracy: 0.8920 - val_loss: 0.8726 - val_accuracy: 0.7311\n",
      "Epoch 23/5000\n",
      "533/533 [==============================] - 6s 12ms/step - loss: 0.2641 - accuracy: 0.9000 - val_loss: 0.9037 - val_accuracy: 0.6920\n",
      "Epoch 24/5000\n",
      "533/533 [==============================] - 7s 13ms/step - loss: 0.2419 - accuracy: 0.9076 - val_loss: 0.8137 - val_accuracy: 0.7184\n",
      "Epoch 25/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.2319 - accuracy: 0.9130 - val_loss: 0.8540 - val_accuracy: 0.7269\n",
      "Epoch 26/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.2217 - accuracy: 0.9181 - val_loss: 0.9156 - val_accuracy: 0.7084\n",
      "Epoch 27/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.2105 - accuracy: 0.9218 - val_loss: 0.9990 - val_accuracy: 0.7443\n",
      "Epoch 28/5000\n",
      "533/533 [==============================] - 6s 12ms/step - loss: 0.2109 - accuracy: 0.9227 - val_loss: 1.1222 - val_accuracy: 0.5938\n",
      "Epoch 29/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1878 - accuracy: 0.9293 - val_loss: 0.9668 - val_accuracy: 0.7427\n",
      "Epoch 30/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1690 - accuracy: 0.9384 - val_loss: 0.9688 - val_accuracy: 0.7554\n",
      "Epoch 31/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1716 - accuracy: 0.9386 - val_loss: 1.1377 - val_accuracy: 0.6228\n",
      "Epoch 32/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1573 - accuracy: 0.9441 - val_loss: 1.0050 - val_accuracy: 0.7285\n",
      "Epoch 33/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1687 - accuracy: 0.9383 - val_loss: 1.0658 - val_accuracy: 0.7491\n",
      "Epoch 34/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1576 - accuracy: 0.9449 - val_loss: 1.1607 - val_accuracy: 0.6698\n",
      "Epoch 35/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1430 - accuracy: 0.9472 - val_loss: 0.9979 - val_accuracy: 0.7417\n",
      "Epoch 36/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1409 - accuracy: 0.9479 - val_loss: 1.4103 - val_accuracy: 0.5922\n",
      "Epoch 37/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1374 - accuracy: 0.9496 - val_loss: 1.2554 - val_accuracy: 0.7343\n",
      "Epoch 38/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1345 - accuracy: 0.9507 - val_loss: 1.2204 - val_accuracy: 0.7538\n",
      "Epoch 39/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1195 - accuracy: 0.9577 - val_loss: 1.2451 - val_accuracy: 0.6186\n",
      "Epoch 40/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1213 - accuracy: 0.9578 - val_loss: 1.2002 - val_accuracy: 0.6751\n",
      "Epoch 41/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1157 - accuracy: 0.9583 - val_loss: 1.1810 - val_accuracy: 0.6756\n",
      "Epoch 42/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1167 - accuracy: 0.9572 - val_loss: 1.3177 - val_accuracy: 0.7163\n",
      "Epoch 43/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1091 - accuracy: 0.9618 - val_loss: 1.4663 - val_accuracy: 0.6107\n",
      "Epoch 44/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1069 - accuracy: 0.9608 - val_loss: 1.1009 - val_accuracy: 0.7031\n",
      "Epoch 45/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1059 - accuracy: 0.9617 - val_loss: 1.3411 - val_accuracy: 0.7517\n",
      "Epoch 46/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1049 - accuracy: 0.9645 - val_loss: 1.1121 - val_accuracy: 0.6926\n",
      "Epoch 47/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.1016 - accuracy: 0.9628 - val_loss: 1.8977 - val_accuracy: 0.5251\n",
      "Epoch 48/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0955 - accuracy: 0.9661 - val_loss: 1.1065 - val_accuracy: 0.7163\n",
      "Epoch 49/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0975 - accuracy: 0.9647 - val_loss: 1.4955 - val_accuracy: 0.7485\n",
      "Epoch 50/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0863 - accuracy: 0.9675 - val_loss: 1.2584 - val_accuracy: 0.7591\n",
      "Epoch 51/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0900 - accuracy: 0.9687 - val_loss: 1.4222 - val_accuracy: 0.7612\n",
      "Epoch 52/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0866 - accuracy: 0.9695 - val_loss: 1.2258 - val_accuracy: 0.7565\n",
      "Epoch 53/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0875 - accuracy: 0.9688 - val_loss: 1.2368 - val_accuracy: 0.7396\n",
      "Epoch 54/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0836 - accuracy: 0.9705 - val_loss: 1.1843 - val_accuracy: 0.7005\n",
      "Epoch 55/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0798 - accuracy: 0.9699 - val_loss: 1.4473 - val_accuracy: 0.7544\n",
      "Epoch 56/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0773 - accuracy: 0.9727 - val_loss: 1.3359 - val_accuracy: 0.7338\n",
      "Epoch 57/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0822 - accuracy: 0.9712 - val_loss: 1.2850 - val_accuracy: 0.6952\n",
      "Epoch 58/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0802 - accuracy: 0.9732 - val_loss: 1.2558 - val_accuracy: 0.7507\n",
      "Epoch 59/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0851 - accuracy: 0.9701 - val_loss: 2.0434 - val_accuracy: 0.7290\n",
      "Epoch 60/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0777 - accuracy: 0.9716 - val_loss: 1.3349 - val_accuracy: 0.7559\n",
      "Epoch 61/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0767 - accuracy: 0.9743 - val_loss: 1.1689 - val_accuracy: 0.7480\n",
      "Epoch 62/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0652 - accuracy: 0.9767 - val_loss: 1.1956 - val_accuracy: 0.7554\n",
      "Epoch 63/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0682 - accuracy: 0.9768 - val_loss: 1.2988 - val_accuracy: 0.7533\n",
      "Epoch 64/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 1.2942 - val_accuracy: 0.7285\n",
      "Epoch 65/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0703 - accuracy: 0.9768 - val_loss: 1.2200 - val_accuracy: 0.7507\n",
      "Epoch 66/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 1.8611 - val_accuracy: 0.7422\n",
      "Epoch 67/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0651 - accuracy: 0.9768 - val_loss: 1.2566 - val_accuracy: 0.7412\n",
      "Epoch 68/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0600 - accuracy: 0.9789 - val_loss: 1.3704 - val_accuracy: 0.7079\n",
      "Epoch 69/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0703 - accuracy: 0.9752 - val_loss: 1.4212 - val_accuracy: 0.6492\n",
      "Epoch 70/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0572 - accuracy: 0.9796 - val_loss: 1.1883 - val_accuracy: 0.7369\n",
      "Epoch 71/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0616 - accuracy: 0.9777 - val_loss: 1.2736 - val_accuracy: 0.7190\n",
      "Epoch 72/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 1.5268 - val_accuracy: 0.7623\n",
      "Epoch 73/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0580 - accuracy: 0.9799 - val_loss: 1.4312 - val_accuracy: 0.6550\n",
      "Epoch 74/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0610 - accuracy: 0.9792 - val_loss: 1.2159 - val_accuracy: 0.7565\n",
      "Epoch 75/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0547 - accuracy: 0.9804 - val_loss: 1.2696 - val_accuracy: 0.7385\n",
      "Epoch 76/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0599 - accuracy: 0.9783 - val_loss: 1.5664 - val_accuracy: 0.7628\n",
      "Epoch 77/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0530 - accuracy: 0.9813 - val_loss: 2.2165 - val_accuracy: 0.7332\n",
      "Epoch 78/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0559 - accuracy: 0.9803 - val_loss: 1.3384 - val_accuracy: 0.7496\n",
      "Epoch 79/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0511 - accuracy: 0.9826 - val_loss: 1.6341 - val_accuracy: 0.7264\n",
      "Epoch 80/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0584 - accuracy: 0.9802 - val_loss: 1.5896 - val_accuracy: 0.7485\n",
      "Epoch 81/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0573 - accuracy: 0.9797 - val_loss: 1.4615 - val_accuracy: 0.7507\n",
      "Epoch 82/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0540 - accuracy: 0.9811 - val_loss: 1.5046 - val_accuracy: 0.6894\n",
      "Epoch 83/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 1.4773 - val_accuracy: 0.7544\n",
      "Epoch 84/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0517 - accuracy: 0.9828 - val_loss: 1.5466 - val_accuracy: 0.6730\n",
      "Epoch 85/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0463 - accuracy: 0.9837 - val_loss: 1.3115 - val_accuracy: 0.7480\n",
      "Epoch 86/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 1.5328 - val_accuracy: 0.7528\n",
      "Epoch 87/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 1.5312 - val_accuracy: 0.6820\n",
      "Epoch 88/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0528 - accuracy: 0.9824 - val_loss: 1.7718 - val_accuracy: 0.7480\n",
      "Epoch 89/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0503 - accuracy: 0.9821 - val_loss: 1.3352 - val_accuracy: 0.7184\n",
      "Epoch 90/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0482 - accuracy: 0.9829 - val_loss: 1.4357 - val_accuracy: 0.6535\n",
      "Epoch 91/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0464 - accuracy: 0.9846 - val_loss: 1.3268 - val_accuracy: 0.7660\n",
      "Epoch 92/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0455 - accuracy: 0.9839 - val_loss: 1.2815 - val_accuracy: 0.7422\n",
      "Epoch 93/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0498 - accuracy: 0.9826 - val_loss: 1.3906 - val_accuracy: 0.6751\n",
      "Epoch 94/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0477 - accuracy: 0.9844 - val_loss: 1.3829 - val_accuracy: 0.7618\n",
      "Epoch 95/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 2.0755 - val_accuracy: 0.7533\n",
      "Epoch 96/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 1.4016 - val_accuracy: 0.6830\n",
      "Epoch 97/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0475 - accuracy: 0.9836 - val_loss: 1.4133 - val_accuracy: 0.6915\n",
      "Epoch 98/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0461 - accuracy: 0.9839 - val_loss: 1.2618 - val_accuracy: 0.7396\n",
      "Epoch 99/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0444 - accuracy: 0.9843 - val_loss: 1.4005 - val_accuracy: 0.7570\n",
      "Epoch 100/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 1.3827 - val_accuracy: 0.7480\n",
      "Epoch 101/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0398 - accuracy: 0.9862 - val_loss: 1.5539 - val_accuracy: 0.7538\n",
      "Epoch 102/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0383 - accuracy: 0.9866 - val_loss: 1.3439 - val_accuracy: 0.7628\n",
      "Epoch 103/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0380 - accuracy: 0.9870 - val_loss: 1.4585 - val_accuracy: 0.7433\n",
      "Epoch 104/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0457 - accuracy: 0.9841 - val_loss: 1.3357 - val_accuracy: 0.7538\n",
      "Epoch 105/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 1.3346 - val_accuracy: 0.7258\n",
      "Epoch 106/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0461 - accuracy: 0.9833 - val_loss: 1.4549 - val_accuracy: 0.7528\n",
      "Epoch 107/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0359 - accuracy: 0.9876 - val_loss: 1.4443 - val_accuracy: 0.7676\n",
      "Epoch 108/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0385 - accuracy: 0.9864 - val_loss: 1.6988 - val_accuracy: 0.7549\n",
      "Epoch 109/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 1.3978 - val_accuracy: 0.7274\n",
      "Epoch 110/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0408 - accuracy: 0.9868 - val_loss: 1.6044 - val_accuracy: 0.7554\n",
      "Epoch 111/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 1.3674 - val_accuracy: 0.7375\n",
      "Epoch 112/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 1.7754 - val_accuracy: 0.7491\n",
      "Epoch 113/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0376 - accuracy: 0.9871 - val_loss: 1.7651 - val_accuracy: 0.7544\n",
      "Epoch 114/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0361 - accuracy: 0.9873 - val_loss: 1.4628 - val_accuracy: 0.7470\n",
      "Epoch 115/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0383 - accuracy: 0.9871 - val_loss: 2.1578 - val_accuracy: 0.7385\n",
      "Epoch 116/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0457 - accuracy: 0.9837 - val_loss: 1.6264 - val_accuracy: 0.7544\n",
      "Epoch 117/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 1.4372 - val_accuracy: 0.7427\n",
      "Epoch 118/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 1.3780 - val_accuracy: 0.7533\n",
      "Epoch 119/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0364 - accuracy: 0.9861 - val_loss: 1.4273 - val_accuracy: 0.7686\n",
      "Epoch 120/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 1.5613 - val_accuracy: 0.7406\n",
      "Epoch 121/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0337 - accuracy: 0.9880 - val_loss: 1.4981 - val_accuracy: 0.7205\n",
      "Epoch 122/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0447 - accuracy: 0.9844 - val_loss: 1.3877 - val_accuracy: 0.7396\n",
      "Epoch 123/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 1.6114 - val_accuracy: 0.7147\n",
      "Epoch 124/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 1.3772 - val_accuracy: 0.7427\n",
      "Epoch 125/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0335 - accuracy: 0.9878 - val_loss: 1.3499 - val_accuracy: 0.7274\n",
      "Epoch 126/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 1.5753 - val_accuracy: 0.7211\n",
      "Epoch 127/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 1.4068 - val_accuracy: 0.7559\n",
      "Epoch 128/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0379 - accuracy: 0.9876 - val_loss: 1.4559 - val_accuracy: 0.7253\n",
      "Epoch 129/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 1.5288 - val_accuracy: 0.7728\n",
      "Epoch 130/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 1.6656 - val_accuracy: 0.7533\n",
      "Epoch 131/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 1.5023 - val_accuracy: 0.6730\n",
      "Epoch 132/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0376 - accuracy: 0.9873 - val_loss: 1.7122 - val_accuracy: 0.7485\n",
      "Epoch 133/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 3.7037 - val_accuracy: 0.7116\n",
      "Epoch 134/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0466 - accuracy: 0.9847 - val_loss: 1.3631 - val_accuracy: 0.7639\n",
      "Epoch 135/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 1.3789 - val_accuracy: 0.7628\n",
      "Epoch 136/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 1.5656 - val_accuracy: 0.6339\n",
      "Epoch 137/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 1.7505 - val_accuracy: 0.7565\n",
      "Epoch 138/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 1.4244 - val_accuracy: 0.7496\n",
      "Epoch 139/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 1.3373 - val_accuracy: 0.7517\n",
      "Epoch 140/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0305 - accuracy: 0.9888 - val_loss: 1.3683 - val_accuracy: 0.7364\n",
      "Epoch 141/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 1.6021 - val_accuracy: 0.7554\n",
      "Epoch 142/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 1.4207 - val_accuracy: 0.7501\n",
      "Epoch 143/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 2.1724 - val_accuracy: 0.7607\n",
      "Epoch 144/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 1.9122 - val_accuracy: 0.7575\n",
      "Epoch 145/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0287 - accuracy: 0.9895 - val_loss: 2.2692 - val_accuracy: 0.7475\n",
      "Epoch 146/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 1.6113 - val_accuracy: 0.7544\n",
      "Epoch 147/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 1.7704 - val_accuracy: 0.7549\n",
      "Epoch 148/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0254 - accuracy: 0.9906 - val_loss: 1.5822 - val_accuracy: 0.7528\n",
      "Epoch 149/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0318 - accuracy: 0.9885 - val_loss: 1.8891 - val_accuracy: 0.7522\n",
      "Epoch 150/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0296 - accuracy: 0.9894 - val_loss: 1.7303 - val_accuracy: 0.7301\n",
      "Epoch 151/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0273 - accuracy: 0.9904 - val_loss: 1.6003 - val_accuracy: 0.7512\n",
      "Epoch 152/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 1.8068 - val_accuracy: 0.7565\n",
      "Epoch 153/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 2.5884 - val_accuracy: 0.7364\n",
      "Epoch 154/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 1.6839 - val_accuracy: 0.6952\n",
      "Epoch 155/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 1.4997 - val_accuracy: 0.6730\n",
      "Epoch 156/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 1.7752 - val_accuracy: 0.7618\n",
      "Epoch 157/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0334 - accuracy: 0.9898 - val_loss: 1.4544 - val_accuracy: 0.7264\n",
      "Epoch 158/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 1.4112 - val_accuracy: 0.7575\n",
      "Epoch 159/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0349 - accuracy: 0.9888 - val_loss: 1.4482 - val_accuracy: 0.7047\n",
      "Epoch 160/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 1.6883 - val_accuracy: 0.7618\n",
      "Epoch 161/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0345 - accuracy: 0.9888 - val_loss: 1.3664 - val_accuracy: 0.7591\n",
      "Epoch 162/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 1.3595 - val_accuracy: 0.7544\n",
      "Epoch 163/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 1.7992 - val_accuracy: 0.7575\n",
      "Epoch 164/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 1.6366 - val_accuracy: 0.7517\n",
      "Epoch 165/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0277 - accuracy: 0.9898 - val_loss: 1.6318 - val_accuracy: 0.7586\n",
      "Epoch 166/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 1.3870 - val_accuracy: 0.7501\n",
      "Epoch 167/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 1.5549 - val_accuracy: 0.7454\n",
      "Epoch 168/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 1.4822 - val_accuracy: 0.7639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 1.6618 - val_accuracy: 0.7301\n",
      "Epoch 170/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 1.3684 - val_accuracy: 0.7485\n",
      "Epoch 171/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0257 - accuracy: 0.9910 - val_loss: 1.6768 - val_accuracy: 0.7496\n",
      "Epoch 172/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 1.3806 - val_accuracy: 0.7575\n",
      "Epoch 173/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 1.7230 - val_accuracy: 0.7559\n",
      "Epoch 174/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 1.7527 - val_accuracy: 0.6730\n",
      "Epoch 175/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 1.9177 - val_accuracy: 0.7406\n",
      "Epoch 176/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 1.4321 - val_accuracy: 0.7570\n",
      "Epoch 177/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0261 - accuracy: 0.9908 - val_loss: 1.5129 - val_accuracy: 0.7501\n",
      "Epoch 178/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 1.4957 - val_accuracy: 0.7575\n",
      "Epoch 179/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0202 - accuracy: 0.9924 - val_loss: 1.5852 - val_accuracy: 0.7528\n",
      "Epoch 180/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 1.7513 - val_accuracy: 0.7602\n",
      "Epoch 181/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 1.5992 - val_accuracy: 0.7570\n",
      "Epoch 182/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 1.4935 - val_accuracy: 0.7575\n",
      "Epoch 183/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0225 - accuracy: 0.9917 - val_loss: 1.5084 - val_accuracy: 0.7496\n",
      "Epoch 184/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 1.8430 - val_accuracy: 0.7618\n",
      "Epoch 185/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0246 - accuracy: 0.9907 - val_loss: 1.8060 - val_accuracy: 0.7586\n",
      "Epoch 186/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 2.0903 - val_accuracy: 0.7581\n",
      "Epoch 187/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 1.6664 - val_accuracy: 0.7179\n",
      "Epoch 188/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 1.4942 - val_accuracy: 0.7538\n",
      "Epoch 189/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 2.1812 - val_accuracy: 0.7586\n",
      "Epoch 190/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 2.0854 - val_accuracy: 0.7586\n",
      "Epoch 191/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 2.3156 - val_accuracy: 0.7570\n",
      "Epoch 192/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 1.9654 - val_accuracy: 0.7660\n",
      "Epoch 193/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 2.2707 - val_accuracy: 0.7612\n",
      "Epoch 194/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 1.6045 - val_accuracy: 0.6709\n",
      "Epoch 195/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 1.5656 - val_accuracy: 0.7581\n",
      "Epoch 196/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 1.5928 - val_accuracy: 0.7406\n",
      "Epoch 197/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 1.6236 - val_accuracy: 0.7676\n",
      "Epoch 198/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 1.7568 - val_accuracy: 0.7026\n",
      "Epoch 199/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 1.7028 - val_accuracy: 0.7633\n",
      "Epoch 200/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 1.9486 - val_accuracy: 0.7676\n",
      "Epoch 201/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 1.6243 - val_accuracy: 0.7517\n",
      "Epoch 202/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 1.7386 - val_accuracy: 0.7412\n",
      "Epoch 203/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 1.6306 - val_accuracy: 0.7385\n",
      "Epoch 204/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 1.6035 - val_accuracy: 0.7353\n",
      "Epoch 205/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 2.0611 - val_accuracy: 0.7554\n",
      "Epoch 206/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 1.4773 - val_accuracy: 0.7021\n",
      "Epoch 207/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 1.6641 - val_accuracy: 0.7591\n",
      "Epoch 208/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 1.6410 - val_accuracy: 0.7438\n",
      "Epoch 209/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 1.5943 - val_accuracy: 0.7618\n",
      "Epoch 210/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 1.6198 - val_accuracy: 0.7485\n",
      "Epoch 211/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 2.3375 - val_accuracy: 0.7591\n",
      "Epoch 212/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 1.6053 - val_accuracy: 0.7332\n",
      "Epoch 213/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 1.5786 - val_accuracy: 0.7554\n",
      "Epoch 214/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 1.4850 - val_accuracy: 0.7575\n",
      "Epoch 215/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 1.9054 - val_accuracy: 0.7522\n",
      "Epoch 216/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 1.5554 - val_accuracy: 0.7237\n",
      "Epoch 217/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 2.0846 - val_accuracy: 0.7538\n",
      "Epoch 218/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0193 - accuracy: 0.9924 - val_loss: 1.8174 - val_accuracy: 0.7586\n",
      "Epoch 219/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 1.4782 - val_accuracy: 0.7544\n",
      "Epoch 220/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0217 - accuracy: 0.9924 - val_loss: 1.4629 - val_accuracy: 0.7448\n",
      "Epoch 221/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 1.6256 - val_accuracy: 0.7602\n",
      "Epoch 222/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 1.9362 - val_accuracy: 0.7628\n",
      "Epoch 223/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 1.5874 - val_accuracy: 0.7581\n",
      "Epoch 224/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 1.7122 - val_accuracy: 0.7559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 1.8973 - val_accuracy: 0.7623\n",
      "Epoch 226/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 2.2957 - val_accuracy: 0.7612\n",
      "Epoch 227/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 1.7378 - val_accuracy: 0.7691\n",
      "Epoch 228/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 1.7988 - val_accuracy: 0.7618\n",
      "Epoch 229/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 2.0614 - val_accuracy: 0.7591\n",
      "Epoch 230/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 1.7746 - val_accuracy: 0.7734\n",
      "Epoch 231/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 1.6676 - val_accuracy: 0.7655\n",
      "Epoch 232/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 1.6114 - val_accuracy: 0.7639\n",
      "Epoch 233/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 1.6686 - val_accuracy: 0.7559\n",
      "Epoch 234/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 2.6566 - val_accuracy: 0.7570\n",
      "Epoch 235/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 2.0694 - val_accuracy: 0.6244\n",
      "Epoch 236/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 1.5530 - val_accuracy: 0.7633\n",
      "Epoch 237/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 1.4584 - val_accuracy: 0.7602\n",
      "Epoch 238/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 1.8173 - val_accuracy: 0.7596\n",
      "Epoch 239/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 1.5521 - val_accuracy: 0.7475\n",
      "Epoch 240/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 1.4596 - val_accuracy: 0.7364\n",
      "Epoch 241/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 1.6563 - val_accuracy: 0.7660\n",
      "Epoch 242/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 1.9484 - val_accuracy: 0.7723\n",
      "Epoch 243/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 1.6415 - val_accuracy: 0.7612\n",
      "Epoch 244/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 1.9081 - val_accuracy: 0.7596\n",
      "Epoch 245/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 2.3302 - val_accuracy: 0.7517\n",
      "Epoch 246/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 2.3558 - val_accuracy: 0.7639\n",
      "Epoch 247/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 1.4756 - val_accuracy: 0.7343\n",
      "Epoch 248/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 1.7644 - val_accuracy: 0.7660\n",
      "Epoch 249/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0201 - accuracy: 0.9925 - val_loss: 1.5025 - val_accuracy: 0.7596\n",
      "Epoch 250/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 1.6934 - val_accuracy: 0.7713\n",
      "Epoch 251/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 1.3928 - val_accuracy: 0.7480\n",
      "Epoch 252/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0309 - accuracy: 0.9894 - val_loss: 1.7028 - val_accuracy: 0.7618\n",
      "Epoch 253/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 1.7436 - val_accuracy: 0.7697\n",
      "Epoch 254/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 1.4594 - val_accuracy: 0.7338\n",
      "Epoch 255/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 1.8087 - val_accuracy: 0.7665\n",
      "Epoch 256/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 2.1655 - val_accuracy: 0.7686\n",
      "Epoch 257/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 1.5459 - val_accuracy: 0.7279\n",
      "Epoch 258/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 1.6066 - val_accuracy: 0.7586\n",
      "Epoch 259/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 1.6524 - val_accuracy: 0.7596\n",
      "Epoch 260/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 1.4536 - val_accuracy: 0.7380\n",
      "Epoch 261/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 1.5682 - val_accuracy: 0.7639\n",
      "Epoch 262/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 1.7093 - val_accuracy: 0.7607\n",
      "Epoch 263/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 1.9063 - val_accuracy: 0.7623\n",
      "Epoch 264/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 1.5763 - val_accuracy: 0.7628\n",
      "Epoch 265/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 1.6197 - val_accuracy: 0.7438\n",
      "Epoch 266/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 1.5487 - val_accuracy: 0.7538\n",
      "Epoch 267/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 1.5346 - val_accuracy: 0.7607\n",
      "Epoch 268/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 1.8060 - val_accuracy: 0.7559\n",
      "Epoch 269/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 1.5187 - val_accuracy: 0.7422\n",
      "Epoch 270/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 2.0637 - val_accuracy: 0.7623\n",
      "Epoch 271/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 1.6819 - val_accuracy: 0.7612\n",
      "Epoch 272/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 1.5965 - val_accuracy: 0.7665\n",
      "Epoch 273/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 1.5023 - val_accuracy: 0.7221\n",
      "Epoch 274/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 1.5726 - val_accuracy: 0.7021\n",
      "Epoch 275/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 1.6596 - val_accuracy: 0.7676\n",
      "Epoch 276/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 2.0140 - val_accuracy: 0.7618\n",
      "Epoch 277/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 1.6617 - val_accuracy: 0.7628\n",
      "Epoch 278/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 1.6938 - val_accuracy: 0.7522\n",
      "Epoch 279/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 2.2868 - val_accuracy: 0.7612\n",
      "Epoch 280/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 1.9325 - val_accuracy: 0.7581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 1.7501 - val_accuracy: 0.7633\n",
      "Epoch 282/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 2.2430 - val_accuracy: 0.7596\n",
      "Epoch 283/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 1.9777 - val_accuracy: 0.7612\n",
      "Epoch 284/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 1.7875 - val_accuracy: 0.7602\n",
      "Epoch 285/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 2.0073 - val_accuracy: 0.7596\n",
      "Epoch 286/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 1.6143 - val_accuracy: 0.7496\n",
      "Epoch 287/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 1.6286 - val_accuracy: 0.7443\n",
      "Epoch 288/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.6540 - val_accuracy: 0.7522\n",
      "Epoch 289/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 1.7691 - val_accuracy: 0.7565\n",
      "Epoch 290/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 1.5392 - val_accuracy: 0.7390\n",
      "Epoch 291/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 1.6150 - val_accuracy: 0.7586\n",
      "Epoch 292/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 1.6633 - val_accuracy: 0.7559\n",
      "Epoch 293/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 2.1941 - val_accuracy: 0.7501\n",
      "Epoch 294/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 1.8118 - val_accuracy: 0.7618\n",
      "Epoch 295/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.7262 - val_accuracy: 0.7507\n",
      "Epoch 296/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 2.4522 - val_accuracy: 0.7591\n",
      "Epoch 297/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 1.5120 - val_accuracy: 0.7633\n",
      "Epoch 298/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 1.5475 - val_accuracy: 0.7750\n",
      "Epoch 299/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 1.9106 - val_accuracy: 0.7776\n",
      "Epoch 300/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 1.8417 - val_accuracy: 0.7734\n",
      "Epoch 301/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 1.5578 - val_accuracy: 0.7470\n",
      "Epoch 302/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 1.6535 - val_accuracy: 0.7279\n",
      "Epoch 303/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.7147 - val_accuracy: 0.7623\n",
      "Epoch 304/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 1.5200 - val_accuracy: 0.7575\n",
      "Epoch 305/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 1.7718 - val_accuracy: 0.7670\n",
      "Epoch 306/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 1.4950 - val_accuracy: 0.7549\n",
      "Epoch 307/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 1.5675 - val_accuracy: 0.7480\n",
      "Epoch 308/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0184 - accuracy: 0.9934 - val_loss: 1.7093 - val_accuracy: 0.7639\n",
      "Epoch 309/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 1.7007 - val_accuracy: 0.7702\n",
      "Epoch 310/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 1.6634 - val_accuracy: 0.7586\n",
      "Epoch 311/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 1.6930 - val_accuracy: 0.7676\n",
      "Epoch 312/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 1.6098 - val_accuracy: 0.7390\n",
      "Epoch 313/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0163 - accuracy: 0.9937 - val_loss: 2.4990 - val_accuracy: 0.7665\n",
      "Epoch 314/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 1.6428 - val_accuracy: 0.7364\n",
      "Epoch 315/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 1.8307 - val_accuracy: 0.7665\n",
      "Epoch 316/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 2.7461 - val_accuracy: 0.7565\n",
      "Epoch 317/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 1.9271 - val_accuracy: 0.7686\n",
      "Epoch 318/5000\n",
      "533/533 [==============================] - 6s 11ms/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 1.9034 - val_accuracy: 0.7713\n",
      "Epoch 319/5000\n",
      "251/533 [=============>................] - ETA: 3s - loss: 0.0152 - accuracy: 0.9940"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90381/4226715820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras import callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "\n",
    "fecha=str(date.today().year)+str(date.today().month)+str(date.today().day)    \n",
    "symbol = 'other_emotions'\n",
    "h5 = symbol + fecha + '_v4[fea-ang-dis-neu].h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                       monitor='loss',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True,\n",
    "                                       #save_weights_only=True,\n",
    "                                       mode='auto',\n",
    "                                       save_freq=1)\n",
    "callback = [checkpoint]\n",
    "\n",
    "modelo = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 5000,callbacks = callback,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5dbceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/predict/\"]\n",
    "# data_pred  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs_pred = []\n",
    "state_pred = []\n",
    "im_pred = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b355f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs_pred.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": get_emotion(item,True)}for p in listdir(f\"{path}{item}\")])\n",
    "            #state_pred.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "31d91a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "22f61c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "777cc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('intial_emotions_2_20211116_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "22327b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pred_ = []\n",
    "state_pred = []\n",
    "for p in imgs_pred:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.05, 5)\n",
    "    if len(faces)>0:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_pred_.append(recortada)\n",
    "            state_pred.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_pred_ = [el/255 for el in imgs_pred_]\n",
    "imgs_pred_ = np.array(imgs_pred_)\n",
    "imgs_pred_= imgs_pred_.reshape((len(imgs_pred_),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5ad51f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ac6f59d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1beb9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0203ae77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e4598990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8096431e-11, 8.9898246e-04, 1.0062725e-08, 9.9910104e-01],\n",
       "       [4.7656874e-12, 4.1784510e-01, 1.1044306e-02, 5.7111061e-01],\n",
       "       [9.9592125e-01, 3.7983016e-03, 2.8208031e-12, 2.8042117e-04],\n",
       "       [1.0165893e-04, 2.5761712e-02, 7.8899723e-07, 9.7413582e-01],\n",
       "       [1.5893158e-06, 1.0128866e-01, 3.8984188e-04, 8.9831996e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ddb2d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1,\n",
       "       0, 0, 3, 0, 0, 0, 2, 0, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1,\n",
       "       2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax(axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2f2183a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= y_dummies.columns\n",
    "cats = [x.replace(\"0_\",\"\") for x in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "30eb031c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happiness', 'other', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "07d087b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b07eefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise happiness\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise other\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise other\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "other sadness\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other sadness\n",
      "other other\n",
      "other sadness\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other sadness\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other sadness\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other sadness\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other sadness\n",
      "other sadness\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness sadness\n",
      "happiness other\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness surprise\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness sadness\n",
      "happiness happiness\n",
      "other surprise\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "other sadness\n",
      "other other\n",
      "other other\n",
      "other surprise\n",
      "other other\n",
      "other other\n",
      "other other\n",
      "sadness sadness\n",
      "sadness other\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness other\n",
      "sadness other\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness other\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness other\n",
      "sadness other\n",
      "sadness sadness\n",
      "sadness other\n"
     ]
    }
   ],
   "source": [
    "states_model = []\n",
    "i=0\n",
    "for i in range(len(prediction)):\n",
    "    states_model.append(cats[prediction[i].argmax()])\n",
    "    print(state_pred[i],cats[prediction[i].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "839cc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5f8a8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046875"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(state_pred,states_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "33581e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "81e2eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(states_model, state_pred)\n",
    "conf = pd.DataFrame(conf,columns=cats, index=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9930098c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "heatmap = sns.heatmap(conf, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec979b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5734112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
