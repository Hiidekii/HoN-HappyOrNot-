{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9db5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import face_recognition as fr\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from os import remove\n",
    "face_cascade = cv2.CascadeClassifier('gui_2/assets/haarcascade_frontalface_default.xml')\n",
    "HEIGHT, WIDTH =48,48\n",
    "other_emotions =  [ 'fear', 'disgust','anger']\n",
    "initial_emotions = ['sadness','happiness', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3c360950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(x,initial):\n",
    "    if initial:\n",
    "        if x in initial_emotions:\n",
    "            return x\n",
    "        else:\n",
    "            return \"other\"\n",
    "    else: \n",
    "        if x in other_emotions:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6a9ac7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/all/train/\",\"data/all/test/\"]#[\"data/CK_cut/\"]#[\"data/all/train/\",\"data/all/test/\"]# #[\"data/CK+/\",\"data/fer/train/\"]\n",
    "# data  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs = []\n",
    "state = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735199f0",
   "metadata": {},
   "source": [
    "## Datos para entrenar emociones iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "355c9697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise\n",
      "disgust\n",
      "anger\n",
      "neutral\n",
      "happiness\n",
      "fear\n",
      "sadness\n",
      "surprise\n",
      "disgust\n",
      "anger\n",
      "neutral\n",
      "happiness\n",
      "fear\n",
      "sadness\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        print(item)\n",
    "        if item not in ignore:\n",
    "            if item in initial_emotions:\n",
    "                imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "                state.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "#             else:\n",
    "#                 imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "#                 state.extend([\"other\" for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "94ff9d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39562, 39562)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state),len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0951941b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fear', 'happiness', 'neutral', 'sadness', 'surprise'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10c87b",
   "metadata": {},
   "source": [
    "## Datos para entrenar resto emociones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367dfb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise\n",
      "disgust\n",
      "anger\n",
      "neutral\n",
      "happiness\n",
      "fear\n",
      "sadness\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        print(item)\n",
    "        if item not in ignore:\n",
    "            if item in other_emotions:\n",
    "                imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "                state.extend([item for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6c9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470,\n",
       " {'anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs),set(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fae39",
   "metadata": {},
   "source": [
    "## *********************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "75e892e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = []\n",
    "try:\n",
    "    imgs_ = []\n",
    "    for p in imgs:\n",
    "        temp = Image.open(p)\n",
    "        save = temp.copy()\n",
    "        imgs_.append(save)\n",
    "        temp.close()\n",
    "except:\n",
    "    errs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "54a50273",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = []\n",
    "HEIGHT, WIDTH =48,48\n",
    "for f in imgs_:\n",
    "    img = f.convert(\"L\").resize((HEIGHT, WIDTH))\n",
    "    imgs_array.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bdd1a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = [el/255 for el in imgs_array]\n",
    "imgs_array = np.array(imgs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "79f7f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array= imgs_array.reshape((len(imgs_array),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "207647b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39562, 48, 48, 1)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b8bfe",
   "metadata": {},
   "source": [
    "## Con este modo de cargar imagenes, filtramos caras con cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs = []\n",
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": get_emotion(item,True)}for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32166a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ = []\n",
    "state = []\n",
    "for p in imgs:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.1, 5) #1.1 factor scale, cuanto  disminuye imagen entre pasos\n",
    "                                                        #5 MIN nEIGHBORS cuantos vecinos cada posible \n",
    "                                                        # rectangulo considerar para prediccion\n",
    "                                                        # (valor minimo px de la cara detectada)\n",
    "                                                        # (valor maximo px)\n",
    "            \n",
    "    if len(faces)==1:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_.append(recortada)\n",
    "            state.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_ = [el/255 for el in imgs_]\n",
    "imgs_array = np.array(imgs_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61537e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array= imgs_array.reshape((len(imgs_array),48,48,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b221d9",
   "metadata": {},
   "source": [
    "# Preparamos entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b65e3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(state)\n",
    "y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f5764951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_happiness</th>\n",
       "      <th>0_neutral</th>\n",
       "      <th>0_sadness</th>\n",
       "      <th>0_surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39557</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39558</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39559</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39561</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39562 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0_happiness  0_neutral  0_sadness  0_surprise\n",
       "0                0          0          0           1\n",
       "1                0          0          0           1\n",
       "2                0          0          0           1\n",
       "3                0          0          0           1\n",
       "4                0          0          0           1\n",
       "...            ...        ...        ...         ...\n",
       "39557            0          0          1           0\n",
       "39558            0          0          1           0\n",
       "39559            0          0          1           0\n",
       "39560            0          0          1           0\n",
       "39561            0          0          1           0\n",
       "\n",
       "[39562 rows x 4 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "335e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array,y_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2b5d459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,BatchNormalization,Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19d26d",
   "metadata": {},
   "source": [
    "# MODELO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "751fe068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 1-conv\n",
    "model.add(Conv2D(64,(3,3),padding='same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2-conv\n",
    "model.add(Conv2D(128,(5,5),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(len(set(state)),activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8cea2",
   "metadata": {},
   "source": [
    "# MODELO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Flatten())\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(imgs_array.shape[1:])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu', input_shape=(imgs_array.shape[1:])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(set(state), activation='softmax'))\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86542935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 200\n",
    "# # steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "# # validation_steps = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "# checkpoint = ModelCheckpoint(\"modelo_ck_fc_tfeid_p1.h5\",monitor='val_accuracy',\n",
    "#                             save_weights_only=False,save_best_only=True, model='max',verbose=1)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=3,min_lr=0.000001,model='auto')\n",
    "\n",
    "# callbacks = [PlotLossesCallback(),checkpoint,reduce_lr]\n",
    "# history = model.fit(X_train,y_train,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=(X_test,y_test),\n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ed763968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "835/835 [==============================] - 273s 326ms/step - loss: 1.0624 - accuracy: 0.5659 - val_loss: 0.8499 - val_accuracy: 0.6365\n",
      "Epoch 2/5000\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 0.7629 - accuracy: 0.6950 - val_loss: 0.8073 - val_accuracy: 0.6944\n",
      "Epoch 3/5000\n",
      "835/835 [==============================] - 12s 15ms/step - loss: 0.6802 - accuracy: 0.7292 - val_loss: 0.6985 - val_accuracy: 0.7099\n",
      "Epoch 4/5000\n",
      "835/835 [==============================] - 11s 13ms/step - loss: 0.6246 - accuracy: 0.7521 - val_loss: 0.5888 - val_accuracy: 0.7564\n",
      "Epoch 5/5000\n",
      "835/835 [==============================] - 11s 13ms/step - loss: 0.5924 - accuracy: 0.7661 - val_loss: 0.8593 - val_accuracy: 0.6395\n",
      "Epoch 6/5000\n",
      "835/835 [==============================] - 9s 11ms/step - loss: 0.5671 - accuracy: 0.7766 - val_loss: 1.2080 - val_accuracy: 0.4057\n",
      "Epoch 7/5000\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 0.5443 - accuracy: 0.7823 - val_loss: 0.7929 - val_accuracy: 0.6904\n",
      "Epoch 8/5000\n",
      "835/835 [==============================] - 9s 11ms/step - loss: 0.5166 - accuracy: 0.7946 - val_loss: 0.7094 - val_accuracy: 0.7571\n",
      "Epoch 9/5000\n",
      "835/835 [==============================] - 10s 11ms/step - loss: 0.4864 - accuracy: 0.8100 - val_loss: 0.6092 - val_accuracy: 0.7517\n",
      "Epoch 10/5000\n",
      "835/835 [==============================] - 11s 13ms/step - loss: 0.4634 - accuracy: 0.8179 - val_loss: 0.5752 - val_accuracy: 0.7695\n",
      "Epoch 11/5000\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 0.4330 - accuracy: 0.8334 - val_loss: 0.6859 - val_accuracy: 0.7284\n",
      "Epoch 12/5000\n",
      "835/835 [==============================] - 10s 11ms/step - loss: 0.4112 - accuracy: 0.8395 - val_loss: 0.7272 - val_accuracy: 0.7123\n",
      "Epoch 13/5000\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 0.3887 - accuracy: 0.8494 - val_loss: 0.5403 - val_accuracy: 0.7840\n",
      "Epoch 14/5000\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 0.3613 - accuracy: 0.8589 - val_loss: 0.6292 - val_accuracy: 0.7685\n",
      "Epoch 15/5000\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 0.3418 - accuracy: 0.8695 - val_loss: 0.5455 - val_accuracy: 0.7989\n",
      "Epoch 16/5000\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 0.3224 - accuracy: 0.8768 - val_loss: 0.6326 - val_accuracy: 0.7642\n",
      "Epoch 17/5000\n",
      "835/835 [==============================] - 9s 11ms/step - loss: 0.2956 - accuracy: 0.8873 - val_loss: 0.6446 - val_accuracy: 0.7766\n",
      "Epoch 18/5000\n",
      "835/835 [==============================] - 9s 11ms/step - loss: 0.2789 - accuracy: 0.8930 - val_loss: 0.8050 - val_accuracy: 0.7099\n",
      "Epoch 19/5000\n",
      "835/835 [==============================] - 9s 11ms/step - loss: 0.2558 - accuracy: 0.9012 - val_loss: 0.6786 - val_accuracy: 0.7466\n",
      "Epoch 20/5000\n",
      "835/835 [==============================] - 9s 11ms/step - loss: 0.2421 - accuracy: 0.9081 - val_loss: 0.7745 - val_accuracy: 0.7126\n",
      "Epoch 21/5000\n",
      "196/835 [======>.......................] - ETA: 7s - loss: 0.2152 - accuracy: 0.9173"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6097/2569784564.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras import callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "\n",
    "fecha=str(date.today().year)+str(date.today().month)+str(date.today().day)    \n",
    "symbol = 'no_dig_no_fear'\n",
    "h5 = symbol + fecha + '_v1.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                       monitor='loss',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True,\n",
    "                                       #save_weights_only=True,\n",
    "                                       mode='auto',\n",
    "                                       save_freq=1)\n",
    "callback = [checkpoint]\n",
    "\n",
    "modelo = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 5000,callbacks = callback,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5dbceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/predict/\"]\n",
    "# data_pred  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs_pred = []\n",
    "state_pred = []\n",
    "im_pred = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b355f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            if item in initial_emotions:\n",
    "                imgs_pred.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": get_emotion(item,True)}for p in listdir(f\"{path}{item}\")])\n",
    "                #state_pred.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "31d91a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "22f61c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "777cc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('intial_emotions_2_20211116_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "22327b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pred_ = []\n",
    "state_pred = []\n",
    "for p in imgs_pred:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.05, 5)\n",
    "    if len(faces)>0:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_pred_.append(recortada)\n",
    "            state_pred.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_pred_ = [el/255 for el in imgs_pred_]\n",
    "imgs_pred_ = np.array(imgs_pred_)\n",
    "imgs_pred_= imgs_pred_.reshape((len(imgs_pred_),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5ad51f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ac6f59d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1beb9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0203ae77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e4598990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6455386e-09, 2.5123241e-05, 6.9271401e-08, 9.9997473e-01],\n",
       "       [2.6155356e-05, 1.2993286e-05, 9.7351753e-05, 9.9986351e-01],\n",
       "       [9.9945217e-01, 1.1151942e-05, 3.2062712e-12, 5.3664343e-04],\n",
       "       [5.9360741e-07, 5.3291876e-07, 6.7491318e-10, 9.9999893e-01],\n",
       "       [4.0267386e-07, 8.5783859e-06, 3.7258883e-06, 9.9998736e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ddb2d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2,\n",
       "       2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax(axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2f2183a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= y_dummies.columns\n",
    "cats = [x.replace(\"0_\",\"\") for x in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "30eb031c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happiness', 'neutral', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "07d087b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b07eefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise happiness\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral sadness\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral happiness\n",
      "neutral happiness\n",
      "neutral happiness\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral sadness\n",
      "neutral happiness\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness sadness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "sadness neutral\n",
      "sadness neutral\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness neutral\n",
      "sadness neutral\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness neutral\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness neutral\n",
      "sadness sadness\n",
      "sadness neutral\n"
     ]
    }
   ],
   "source": [
    "states_model = []\n",
    "i=0\n",
    "for i in range(len(prediction)):\n",
    "    states_model.append(cats[prediction[i].argmax()])\n",
    "    print(state_pred[i],cats[prediction[i].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "839cc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5f8a8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.810126582278481"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(state_pred,states_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "33581e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "81e2eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(states_model, state_pred)\n",
    "conf = pd.DataFrame(conf,columns=cats, index=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9930098c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAJDCAYAAAARsv49AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzH0lEQVR4nO3deZhcZZX48e/pELYgSwgCCRlZXQBljyD4E5RdtlEBURSQmegICi4oMyI6uAzqDCrqgFEwiCCggmxBQAbZBGWRLeyBIFkAQUOQsCTp8/ujbrAIna7bnVRXv+nv53nu03Vv3Vv3VG666u3znve9kZlIkiSVqKvTAUiSJPWXDRlJklQsGzKSJKlYNmQkSVKxbMhIkqRi2ZCRJEnFsiEjSZKWiIgYGxFXR8S9ETE5Io6qto+MiCsj4sHq52qLOH73iLg/Ih6KiGNrndN5ZCRJ0pIQEWsDa2fmbRHxGuBWYD/gUOCvmXli1UBZLTM/v9Cxw4AHgF2AacDNwEGZeU9v5zQjI0mSlojMnJmZt1WPnwXuBcYA+wJnVLudQaNxs7BxwEOZ+XBmvgScUx3XKxsykiRpiYuIdYEtgD8Aa2bmTGg0doDX9nDIGOCxpvVp1bZeLbPYkbbw4gPX23dVsPftfGKnQ1A/Xfb4nzodghbDqsuP6HQIWgxPzX4gBvJ8c596eMC+a5ddY4OPAuObNk3IzAnN+0TESsCvgKMzc3ZErX+OnnZq+b7a3pCRJElLj6rRMmFRz0fEcBqNmLMy8/xq8xMRsXZmzqzqaJ7s4dBpwNim9XWAGa3isWtJkqTSdc8fuKUX0Ui9nAbcm5knNT11EXBI9fgQ4MIeDr8Z2Cgi1ouIZYH3V8f1yoaMJElaUrYHPgS8MyJur5Y9gROBXSLiQRqjkk4EiIjRETEJIDPnAUcCl9MoEj4vMye3OqFdS5IklS67Ox0BAJl5PT3XugC8q4f9ZwB7Nq1PAib15ZxmZCRJUrFsyEiSpGLZtSRJUum6B0fXUieYkZEkScUyIyNJUuFykBT7doIZGUmSVCwzMpIklc4aGUmSpPKYkZEkqXTWyEiSJJXHjIwkSaVrcTPHpZkZGUmSVCwzMpIklc4aGUmSpPKYkZEkqXTOIyNJklQeMzKSJBXOey1JkiQVyIaMJEkqll1LkiSVzmJfSZKk8piRkSSpdBb7SpIklceMjCRJpfOmkZIkSeUxIyNJUumskZEkSSqPGRlJkkrnPDKSJEnlMSMjSVLprJGRJEkqjxkZSZJKZ42MJElSeczISJJUuExn9pUkSSqODRlJklQsu5YkSSqdw68lSZLKY0ZGkqTSOfxakiSpPLUyMhExAng+M7sj4vXAG4HLMnNuW6OTJEmtWSPT0rXA8hExBrgKOAyY2K6gJEmS6qhbIxOZOSciDge+l5nfjIg/tTMwSZJUU7cT4rUSEbEd8EHg0mqbhcKSJKmj6jZGjgb+HbggMydHxPrA1W2LSpIk1TeEa2RqNWQy8xrgGoCI6AKeysxPtjMwSZKkVmp1LUXE2RGxcjV66R7g/og4pr2hSZKkWrq7B24ZZOrWyGycmbOB/YBJwD8BH2pXUJIkSXXUrZEZHhHDaTRkvp+ZcyMi2xeWJEmqbQjXyNTNyPwQmAqMAK6NiNcBs9sVlCRJUh11i31PBk5u2vRoROzUnpAkSVKfDMLalYFSt9h3zYg4LSIuq9Y3Bg5pa2SSJEkt1O1amghcDoyu1h+gMbeMJElSx9RtyIzKzPOAboDMnAcM3fmQJUkaTBx+3dJzEbE6kAARsS3wTNuikiRJqqHu8OtPAxcBG0TEDcAawPvaFpUkSaotc+h2ktQdtXRbRLwDeAMQwP2ZObetkUmSJLXQlztYjwPWrY7ZMiLIzJ+2JSpJklTfIKxdGSh1h1+fCfw3sAOwTbVs3ca4BqXjv3s67zj4aP75iC++vO3+Rx7j4M9+jfcceTxHnnAyf5/zfAcjVF90dXXxnUnf5fifHN/pUNRHu+26I5Pvvpb77rmezx1zRKfDUR989wdf594pN3LdTZd0OhQtJeoW+24NbJ+ZH8/MT1TLkLv79T7v2p5TvvypV2z78skTOfqQ93H+90/gXdttwcTzf9Oh6NRXe39kH6Y99Finw1AfdXV1cfJ3v8Zeex/MmzfbiQMP3I83vWmjToelms4563wOfM/hnQ5j6ZPdA7e0EBGnR8STEXF307ZzI+L2apkaEbcv4tipEXFXtd8tdd563YbM3cBaNfddam296RtY5TUjXrFt6vTH2WrT1wOw3eab8Nvf39qJ0NRHq6+1Otu8axuuOOeKToeiPhq3zRZMmTKVRx75M3PnzuW88y5kn71363RYqunG39/C3/7moNel3ERg9+YNmXlgZm6emZsDvwLO7+X4nap9a/X81K2RGQXcExF/BF5sCmyfmscvtTZ83Rh+94fb2WnbLbjihpt5/Km/djok1fCvXx7PT75+OiuMWLHToaiPRo9Zi8emzXh5fdr0mYzbZosORiQNAoOoRiYzr42IdXt6LiICOAB455I6X92GzJeX1AmXNid88jBOnHA2p55zMTu+dTOGL9OX+ml1wjbv2oZnnprFlLumsOm2b+50OOqjxufgK2VmByKR1A9vB57IzAcX8XwCV0REAj/MzAmtXrDu8Otr6scIETEeGA/w/ROO4V8OXHoTN+uNXZsffuUzQKOb6bqb7+pwRGrlTVtvzLhd3spWO23Nsssty4qvWYFPf+cznHT0/3Q6NNUwfdpMxq4z+uX1dcaszcyZT3QwImkQqFG7sqQ0f8dXJtRpcFQOAn7ey/PbZ+aMiHgtcGVE3JeZ1/b2gr02ZCLi+szcISKepZrVd8FTQGbmyj0dV72hCQAvPnD9Uv2n0tOzZrP6qivT3d3NhHMvYf893tHpkNTCT79xBj/9xhkAbLrtm3nPR//ZRkxBbr7ldjbccD3WXXcs06c/zgEH7MuHPuzIJWmgNH/H90VELAO8B9iql9eeUf18MiIuoDH1S/8bMpm5Q/XzNX0NeGn0uW/9kFvuup9Zs//Ozod+lo9/YF/mvPAC5156NQDv2m5L9tt5hw5HKS3d5s+fz1FHH8ekS89mWFcXE884l3vueaDTYammCaefxPY7jGPk6qtx573X8o2vn8xZZ/6y02GVbxDVyPRiZ+C+zJzW05MRMQLoysxnq8e7Aie0etGo27ccEVvSmEcmgesz8091jlvaMzJLu/ftfGKnQ1A/XfZ4rV9RDVKrLj+i9U4atJ6a/cCri7na6Pkr/nfAvmtX2PXjvb63iPg5sCONgUJPAF/KzNMiYiJwU2ae2rTvaODHmblnRKwPXFA9tQxwdmZ+rVU8tWpkIuJ4YH/+MVxqYkT8IjO/Wud4SZLURgNYI9NKZh60iO2H9rBtBrBn9fhhYLO+nq/uEJuDgC0y8wWAiDgRuA2wISNJkjqm7oR4U4Hlm9aXA6Ys8WgkSZL6oG5G5kVgckRcSaNGZhfg+og4GWAo3q5AkqRBo4xi37ao25C5gH8U4AD8bsmHIkmS1Dd1J8Q7IyKWBd5IIyNzf2a+1NbIJElSPWZkehcRewI/pFEXE8B6EfHRzLysncFJkiT1pm7X0kk07kb5EEBEbABcCtiQkSSp0wbR8OuBVnfU0pMLGjGVh4En2xCPJElSbXUzMpMjYhJwHo0amf2BmyPiPQCZeX5vB0uSpDayRqal5WlMM7zgjoh/AUYCe9No2NiQkSRJA67uqKXD2h2IJEnqpyFcI1N31NLywOHAJjTN8JuZH2lTXJIkSS3VLfY9E1gL2A24BlgHeLZdQUmSpD7o7h64ZZCp25DZMDO/CDyXmWcA7wbe3L6wJEmSWqtb7Du3+jkrIjYFHgfWbUtEkiSpb6yRaWlCRKwGHAdcBKwEfLFtUUmSJNVQtyFzJvBeGlmYM6pta7YjIEmS1EeDsHZloNRtyFwIPAPcCrzYvnAkSZLqq9uQWSczd29rJJIkSX1UtyHz+4h4c2be1dZoJElS39m11LOIuIvGLQiWAQ6LiIdpdC0FkJn5lvaHKEmS1LNWGZm9BiQKSZLUf5mdjqBjem3IZOajAxWIJElSX9WtkZEkSYPVEK6RqXuLAkmSpEHHjIwkSaUzIyNJklQeMzKSJJVuCN800oyMJEkqlhkZSZJKZ42MJElSeczISJJUuiE8s68ZGUmSVCwzMpIklc4aGUmSpPKYkZEkqXRmZCRJkspjQ0aSJBXLriVJkkrnLQokSZLKY0ZGkqTCZbcT4kmSJBXHjIwkSaVz+LUkSVJ5zMhIklQ6Ry1JkiSVx4yMJEmlc9SSJElSeczISJJUOkctSZIklceMjCRJpTMjI0mSVB4zMpIklS4dtSRJklQcGzKSJKlYdi1JklQ6i30lSZLKY0ZGkqTSeYsCSZKk8tiQkSSpdNk9cEsLEXF6RDwZEXc3bftyREyPiNurZc9FHLt7RNwfEQ9FxLF13roNGUmStCRNBHbvYfu3M3Pzapm08JMRMQz4AbAHsDFwUERs3Opk1shIklS6QVQjk5nXRsS6/Th0HPBQZj4MEBHnAPsC9/R2kBkZSZI0EI6MiDurrqfVenh+DPBY0/q0aluv2p6RGbHpge0+hdpo1pFbdToE9dOpv9yp0yFoMRz7+NWdDkEFyQGcRyYixgPjmzZNyMwJLQ47BfgKkNXP/wE+svBL93Bcy1STXUuSJKm2qtHSquGy8DFPLHgcET8CLulht2nA2Kb1dYAZrV7bhowkSaUbRDUyPYmItTNzZrX6z8DdPex2M7BRRKwHTAfeD3yg1WvbkJEkSUtMRPwc2BEYFRHTgC8BO0bE5jS6iqYCH632HQ38ODP3zMx5EXEkcDkwDDg9Mye3Op8NGUmSSldjfpeBkpkH9bD5tEXsOwPYs2l9EvCqodm9cdSSJEkqlhkZSZJKN8hrZNrJjIwkSSqWDRlJklQsu5YkSSrdAE6IN9iYkZEkScUyIyNJUuks9pUkSSqPGRlJkko3iCbEG2hmZCRJUrHMyEiSVDprZCRJkspjRkaSpMKl88hIkiSVx4yMJEmls0ZGkiSpPGZkJEkqnRkZSZKk8piRkSSpdM7sK0mSVB4bMpIkqVh2LUmSVDqLfSVJkspjRkaSpMKlGRlJkqTymJGRJKl0ZmQkSZLKY0ZGkqTSdTshniRJUnHMyEiSVDprZCRJkspjRkaSpNKZkZEkSSqPGRlJkgqXaUZGkiSpOGZkJEkqnTUykiRJ5bEhI0mSimXXkiRJpbNrSZIkqTxmZCRJKlyakZEkSSqPGRlJkkpnRkaSJKk8ZmQkSSpdd6cD6BwzMpIkqVhmZCRJKpyjliRJkgrUa0YmIp4FemrmBZCZuXJbopIkSfUN4YxMrw2ZzHzNQAUiSZLUV32qkYmI1wLLL1jPzD8v8YgkSVLfOGqpdxGxT0Q8CDwCXANMBS5rY1ySJEkt1c3IfAXYFvhtZm4RETsBB7UvLEmSVJejllqbm5lPA10R0ZWZVwObty8sSZKk1upmZGZFxErAtcBZEfEkMK99YUmSJLVWtyGzL/A88Cngg8AqwAntCkqSJPXBEC72bdmQiYhhwIWZuTONf6oz2h6VJElSDS0bMpk5PyLmRMQqmfnMQAQlSZLqs9i3tReAuyLitIg4ecHSzsAGu9123ZHJd1/Lffdcz+eOOaLT4aiF5Q78JCv+509Z4Zjvveq54Tvux0onXQQjnP+xBKutvzYfvuxrLy+fmPwjtjx8t06HpZr87NSSVrdG5tJqaTZkm39dXV2c/N2vsfueBzFt2kxuunESF19yBffe+2CnQ9MizL35KuZefwnLfeBTr9geq45i2Os3p/uvT3YoMvXV3x6eyU/3+AIA0RV87I/f46Hf3NLhqFSHn51tNIhqZCLidGAv4MnM3LTa9i1gb+AlYApwWGbO6uHYqcCzwHxgXmZu3ep8dTMyq2bmGc0LsFrNY5c647bZgilTpvLII39m7ty5nHfeheyzt38RDmbdD08m5/z9VduX2/dwXrpkIkO4XV60f9p+E2b9+UlmT3+606GoBj87h4yJwO4LbbsS2DQz3wI8APx7L8fvlJmb12nEQP2GzCE9bDu05rFLndFj1uKxaTNeXp82fSajR6/VwYjUH8M2GUf3M0/TPWNqp0NRP71xn+2478IbOx2GavKzs32ye+CWlrFkXgv8daFtV2TmgmlbbgLWWVLvvdeGTEQcFBEXA+tFxEVNy9XAkP0TKCJetS3Tv+iLMnxZlt15f176zdmdjkT91DV8GBvssiX3X/qHToeimvzsVOUjLPo2RwlcERG3RsT4Oi/Wqkbm98BMYBTwP03bnwXuXNRB1cnHA8SwVejqGlEnlmJMnzaTseuMfnl9nTFrM3PmEx2MSH3VNWptYuSarPjZ7wIQq4xixU9/h+e/8xny2VmdDU61rLfjZjx591TmPDW706GoJj8722gAa2Sav+MrEzJzQs1jv0BjQt2zFrHL9pk5o7pJ9ZURcV+V4VmkXhsymfko8CiwXZ0Am46bAEwAWGbZMUtdc/vmW25nww3XY911xzJ9+uMccMC+fOjDVt+XpHvmo8z50odfXl/xuB8x59ufhuee7WBU6os37Wu3Umn87Fw6NH/H90VEHEKjCPhduYhUXGbOqH4+GREXAONo3FVgkWqNWoqIZ/lHNeSywHDgucxcuV74S5f58+dz1NHHMenSsxnW1cXEM87lnnse6HRY6sVyB3+WYRtuSoxYmRWPP52XLv858/5wZafDUj8ts/yyvO7tm3LFv5/e6VDUB352tk+d2pVOiojdgc8D78jMOYvYZwTQlZnPVo93pcZdBKI//ZMRsR8wLjP/o9W+S2NGZiiZdeRWnQ5B/XTqL4fk3xlLjWMfv7rTIWgxzHtp+qsLgtroqT3eMWDftaMuu6bX9xYRPwd2pFGW8gTwJRqjlJbjH/W1N2XmxyJiNPDjzNwzItYHLqieXwY4OzO/1iqeuvPIvEJm/joiju3PsZIkaQkbRBmZzDyoh82nLWLfGcCe1eOHgc36er66XUvvaVrtArbGiTckSVKH1c3I7N30eB4wlcYdsSVJUocN9hqZdqrVkMnMw9odiCRJUl/Vmtk3Il4fEVdFxN3V+lsi4rj2hiZJktS7urco+BGNiuO5AJl5J/D+dgUlSZLqG0y3KBhodRsyK2bmHxfaNq/HPSVJkgZI3WLfpyJiA6qRShHxPhq3LpAkSR02GDMlA6VuQ+YIGtMRvzEipgOPAB9sW1SSJEk11G3ITAd+AlwNjARmA4dQY+pgSZLUZjmgEwkPKnUbMhcCs4DbgBlti0aSJKkP6jZk1snM3dsaiSRJ6pehXCNTd9TS7yPizW2NRJIkqY/qZmR2AA6NiEeAF4EAMjPf0rbIJElSLdltjUwre7Q1CkmSpH6oe6+lR9sdiCRJ6h9rZCRJkgpUt2tJkiQNUjmE55ExIyNJkoplRkaSpMJZIyNJklQgGzKSJKlYdi1JklS4oTwhnhkZSZJULDMykiQVLrPTEXSOGRlJklQsMzKSJBXOGhlJkqQCmZGRJKlwZmQkSZIKZEZGkqTCOWpJkiSpQGZkJEkqnDUykiRJBTIjI0lS4TLNyEiSJBXHjIwkSYXL7k5H0DlmZCRJUrFsyEiSpGLZtSRJUuG6LfaVJEkqjxkZSZIK5/BrSZKkApmRkSSpcN6iQJIkqUBmZCRJKlxmpyPoHDMykiSpWGZkJEkqnDUykiRJBTIjI0lS4ZzZV5IkqUBmZCRJKpwz+0qSJBXIjIwkSYVzHhlJkqQC2ZCRJEnFsmtJkqTCOfxakiSpQGZkJEkqnMOvJUmSCmRDRpKkwmUO3NJKRJweEU9GxN1N20ZGxJUR8WD1c7VFHLt7RNwfEQ9FxLF13rsNGUmStCRNBHZfaNuxwFWZuRFwVbX+ChExDPgBsAewMXBQRGzc6mQ2ZCRJKlx3xoAtrWTmtcBfF9q8L3BG9fgMYL8eDh0HPJSZD2fmS8A51XG9siEjSZLabc3MnAlQ/XxtD/uMAR5rWp9WbetV20ctrbr8iHafQm205ZkzOh2C+mnSGi92OgQthlrFAVJlIEctRcR4YHzTpgmZOWFJvHQP21pW5Tj8WpIk1VY1WvracHkiItbOzJkRsTbwZA/7TAPGNq2vA7T8a9quJUmSCjeYamQW4SLgkOrxIcCFPexzM7BRRKwXEcsC76+O65UNGUmStMRExM+BG4E3RMS0iDgcOBHYJSIeBHap1omI0RExCSAz5wFHApcD9wLnZebkVueza0mSpMLVmN5lwGTmQYt46l097DsD2LNpfRIwqS/nMyMjSZKKZUZGkqTCefdrSZKkApmRkSSpcN79WpIkqUA2ZCRJUrHsWpIkqXDdnQ6gg8zISJKkYpmRkSSpcNnj/RaHBjMykiSpWGZkJEkqXPdgukfBADMjI0mSimVGRpKkwnVbIyNJklQeMzKSJBXOUUuSJEkFMiMjSVLhnNlXkiSpQGZkJEkqnDUykiRJBTIjI0lS4ayRkSRJKpANGUmSVCy7liRJKpxdS5IkSQUyIyNJUuEcfi1JklQgMzKSJBWue+gmZMzISJKkcpmRkSSpcN3WyEiSJJXHjIwkSYXLTgfQQWZkJElSsczISJJUOGf2lSRJKpAZGUmSCtcdjlqSJEkqjhkZSZIK56glSZKkAtmQkSRJxbJrSZKkwjn8WpIkqUBmZCRJKlz30B19bUZGkiSVq88ZmYhYDRibmXe2IR5JktRH3QzdlEytjExE/C4iVo6IkcAdwE8i4qT2hiZJktS7ul1Lq2TmbOA9wE8ycytg5/aFJUmS6soBXAabug2ZZSJibeAA4JI2xiNJklRb3RqZE4DLgesz8+aIWB94sH1hSZKkuobyqKVaDZnM/AXwi6b1h4H3tisoSZKkOuoW+36zKvYdHhFXRcRTEXFwu4OTJEmtdQ/gMtjUrZHZtSr23QuYBrweOKZtUUmSJNVQt0ZmePVzT+DnmfnXiCHcISdJ0iAyGEcTDZS6DZmLI+I+4Hng4xGxBvBC+8KSJElqrW6x77ER8Q1gdmbOj4g5wL7tDU2SJNUxlEct1S32XRE4Ajil2jQa2LpdQUmSJNVRt9j3J8BLwNuq9WnAV9sSkSRJUk11GzIbZOY3gbkAmfk8DOE7VEmSNIg4/Lq1lyJiBarC6IjYAHixbVEV4Ls/+Dr3TrmR627yjg2lWWv0mvz0glO57IZfcOl15/Lh8e/vdEhq4bVf/TTrXncuYy/84cvbRuz2dsZeNIEN7r6M5TbZqIPRqS9223VHJt99Lffdcz2fO+aIToejpUDdhsyXgN8AYyPiLOAq4HNti6oA55x1Pge+5/BOh6F+mD9/Hid+6dvssf3+HLD7YXzwI/uzwevX63RY6sXsC65g5vgvvGLbSw9O5fFPnsALt9zVoajUV11dXZz83a+x194H8+bNduLAA/fjTW+yEbokDJaMTES8ISJub1pmR8TRC+2zY0Q807TP8Yvz3uuOWroyIm4DtqXRpXRUZj61OCcu3Y2/v4Wx/zSm02GoH/7yxNP85YmnAXjuuTlMeWAqa679WqY88EiHI9OivHDr3Swzes1XbJv78GMdikb9NW6bLZgyZSqPPPJnAM4770L22Xs37r3XW/ctLTLzfmBzgIgYBkwHLuhh1+syc68lcc66GRmA5YG/AbOBjSPi/y2JAKROGjN2bTZ+8xu449a7Ox2KtNQbPWYtHps24+X1adNnMnr0Wh2MaOmRMXBLH7wLmJKZj7bnXTfUyshUc8gcCEzmH5mlBK5tU1xS2604YgW+95Nv8vXj/ofn/v5cp8ORlno9zQifOZTnpF3qvR/4+SKe2y4i7gBmAJ/NzMn9PUndmX33A96QmbUKfCNiPDAeYMRyr2X5ZVfpX3RSmyyzzDC+95NvcvEvf8MVl17d6XCkIWH6tJmMXWf0y+vrjFmbmTOf6GBES4+BHE3U/B1fmZCZExbaZ1lgH+Dfe3iJ24DXZebfI2JP4NdAv4ul6nYtPcw/7rfUUmZOyMytM3NrGzEajL7+neOZ8sAj/OTUszodijRk3HzL7Wy44Xqsu+5Yhg8fzgEH7MvFl1zR6bDUR83f8dUyoYfd9gBuy8xXtVQzc3Zm/r16PAkYHhGj+htP3YzMHOD2iLiKpmHXmfnJ/p64dBNOP4ntdxjHyNVX4857r+UbXz+Zs878ZafDUg1bvXUz9jvw3dw3+UEuvLrRkDnpa//LNb+9ocORaVHW/NaxrDDuLQxbdRXW/b+f8fT3z6T7mWdZ4wsfZ9jIVVj7lK/w0n1TmLHQyCYNLvPnz+eoo49j0qVnM6yri4lnnMs99zzQ6bCWCoNwfpeDWES3UkSsBTyRmRkR42gkVZ7u74miTv9kRBzS0/bMPKPVsaNWfr0doAUbudzKnQ5B/TRpjdU7HYIWwxsfsgC9ZPNemj6gk8Z+f+zBA/Zde+RjP+v1vVW3NXoMWD8zn6m2fQwgM0+NiCOBfwPm0bgZ9acz8/f9jafu8OuWDRZJktQZgyljkJlzgNUX2nZq0+PvA99fUufrtSETEXfRy79PZr5lSQUiSZLUV60yMgsmq1kwj/SZ1c8P0qibkSRJHdY9hO9+2GtDZsEkNhGxfWZu3/TUsRFxA3BCO4OTJEnqTd3h1yMiYocFKxHxNmBEe0KSJEl9MVjutdQJdYdfHw6cHhELJoWZBXykLRFJkiTVVHfU0q3AZhGxMo0h28+0NyxJkqTW6mZkiIh3A5sAyy+4X0ZmWiMjSVKHDcYun4FSq0YmIk6lcdPITwAB7A+8ro1xSZIktVS32Pdtmflh4G+Z+Z/AdsDY9oUlSZLqygFcBpu6DZkXqp9zImI0jWmF12tPSJIkSfXUrZG5OCJWBb5F4/bbCfyoXUFJkqT6nBCvtfuA+Zn5q4jYGNgS+HXbopIkSaqhbtfSFzPz2WpSvF2AicApbYtKkiTVNpQnxKvbkJlf/Xw3cGpmXggs256QJEmS6qnbkJkeET8EDgAmRcRyfThWkiS1kaOWWjsAuBzYPTNnASOBY9oVlCRJUh11b1EwBzi/aX0mMLNdQUmSpPq6B2WuZGDYPSRJkopV+15LkiRpcBqMo4kGihkZSZJULDMykiQVbuhWyJiRkSRJBbMhI0mSimXXkiRJhbPYV5IkqUBmZCRJKlx3dDqCzjEjI0mSimVGRpKkwnmLAkmSpAKZkZEkqXBDNx9jRkaSJBXMjIwkSYVzHhlJkqQCmZGRJKlwjlqSJEkqkBkZSZIKN3TzMWZkJElSwczISJJUOEctSZIkFciGjCRJKpZdS5IkFc7h15IkSQUyIyNJUuGGbj7GjIwkSSqYGRlJkgrn8GtJkqQCmZGRJKlwOYSrZMzISJKkYpmRkSSpcNbISJIkFciMjCRJhXNmX0mSpAKZkZEkqXBDNx9jRkaSJBXMjIwkSYWzRkaSJKlANmQkSVKx7FqSJKlwTognSZJUIDMykiQVbjDdNDIipgLPAvOBeZm59ULPB/BdYE9gDnBoZt7W3/PZkJEkSUvaTpn51CKe2wPYqFreCpxS/ewXGzKSJBWusBqZfYGfZmYCN0XEqhGxdmbO7M+LWSMjSZKWpASuiIhbI2J8D8+PAR5rWp9WbeuXtmdkZr3wXLtPoTby+pXrjc/0648bDRLPz7iu0yGoIANZI1M1TpobKBMyc0LT+vaZOSMiXgtcGRH3Zea1zS/Rw8v2+w3YtSRJkmqrGi0Tenl+RvXzyYi4ABgHNDdkpgFjm9bXAWb0Nx67liRJKlz3AC69iYgREfGaBY+BXYG7F9rtIuDD0bAt8Ex/62PAjIwkSVpy1gQuaIywZhng7Mz8TUR8DCAzTwUm0Rh6/RCN4deHLc4JbchIklS47hwc88hk5sPAZj1sP7XpcQJHLKlz2rUkSZKKZUZGkqTCDY58TGeYkZEkScUyIyNJUuG6h3BOxoyMJEkqlg0ZSZJULLuWJEkq3EDeomCwMSMjSZKKZUZGkqTCtbp1wNLMjIwkSSqWGRlJkgrn8GtJkqQCmZGRJKlwjlqSJEkqkBkZSZIK56glSZKkApmRkSSpcJnWyEiSJBXHjIwkSYVzHhlJkqQCmZGRJKlwjlqSJEkqkA0ZSZJULLuWJEkqnLcokCRJKpAZGUmSCufwa0mSpAKZkZEkqXDeokCSJKlAZmQkSSqcE+JJkiQVyIyMJEmFcx4ZSZKkApmRkSSpcM4jI0mSVCAzMpIkFc55ZCRJkgpkRkaSpMJZIyNJklQgMzKSJBXOeWQkSZIKZENGkiQVy64lSZIK1+3wa0mSpPKYkZEkqXBDNx9TMyMTEWtGxGkRcVm1vnFEHN7e0CRJknpXt2tpInA5MLpafwA4ug3xSJKkPuomB2wZbOo2ZEZl5nlAN0BmzgPmty0qSZKkGurWyDwXEatTdcNFxLbAM22LSpIk1TYYMyUDpW5D5tPARcAGEXEDsAbwvrZFJUmSVEOthkxm3hYR7wDeAARwf2bObWtkkiSplnQemd5FxP7ACpk5GdgPODcitmxnYJIkSa3ULfb9YmY+GxE7ALsBZwCntC8sSZJUl6OWWlswQundwCmZeSGwbHtCkiRJqqduse/0iPghsDPwjYhYDm9vIEnSoJCDMFMyUOo2Rg6gMSHe7pk5CxgJHNOuoCRJkuroNSMTEStn5mxgeeB31baRwIvALW2PTpIktTSURy216lo6G9gLuJXGZHjR9FwC67cpLkmSpJZ67VrKzL0iIoB3ZOb6mble0zKkGzG77bojk+++lvvuuZ7PHXNEp8NRH3n9yub1K8fMJ/7CYUd+nr0/MJ59P/hRzjzv1wA8M/tZ/uWo/2DPAw/nX476D56Z/WxnA1WxWtbIZCNfdcEAxFKMrq4uTv7u19hr74N582Y7ceCB+/GmN23U6bBUk9evbF6/siwzbBjHfOJfufjsCZw94ducc/4lTHnkUX585nlsu/XmTDr3NLbdenNO+9l5nQ61aINl+HVEjI2IqyPi3oiYHBFH9bDPjhHxTETcXi3HL857r1vse1NEbLM4J1qajNtmC6ZMmcojj/yZuXPnct55F7LP3rt1OizV5PUrm9evLGuMGsnGb9gQgBEjVmT9143lib88zdXX3ci+e+wMwL577Mz/XXtjJ8PUkjMP+ExmvgnYFjgiIjbuYb/rMnPzajlhcU5YtyGzE3BjREyJiDsj4q6IuHNxTlyy0WPW4rFpM15enzZ9JqNHr9XBiNQXXr+yef3KNX3mE9z74BTesskbePpvs1hj1Eig0dj56yzvQ7w4MnPAlhZxzMzM26rHzwL3AmPa+d7rziOzRzuDKE2jbOiVhnLFeGm8fmXz+pVpzpzn+dQXvsrnP/lRVhoxotPhaABExLrAFsAfenh6u4i4A5gBfLa6BVK/1L1p5KPVvZV2oDFa6YYFLa6eRMR4YDxADFuFrq6l6z/t9GkzGbvO6JfX1xmzNjNnPtHBiNQXXr+yef3KM3fePI7+wld59647scuO2wOw+mqr8pen/soao0byl6f+yshVV+lwlGUbyFsHNH/HVyZk5oSF9lkJ+BVwdDWNS7PbgNdl5t8jYk/g10C/C93q3jTyeBr3V1odGAX8JCKOW9T+mTkhM7fOzK2XtkYMwM233M6GG67HuuuOZfjw4RxwwL5cfMkVnQ5LNXn9yub1K0tmcvx/fYf1XzeWQ97/npe377jDtlx42W8BuPCy37LT27frVIjqo+bv+GpZuBEznEYj5qzMPL+H42dn5t+rx5OA4RExqr/x1O1aOgjYIjNfqII8kUaL6qv9PXHJ5s+fz1FHH8ekS89mWFcXE884l3vueaDTYakmr1/ZvH5l+dOdk7n4N1ex0Qbr8t5DGkPlj/roIfzLhw7gM1/8Oudfcjlrr7kGJ331Cx2OtGyD5RYF1ZQtpwH3ZuZJi9hnLeCJzMyIGEcjqfJ0v89Zp285Ii4DDqpuT0BErAr8LDP3anXsMsuOGRz/upJUkOdnXNfpELQYho9a/9XFXG30lrW2G7Dv2jsfv3GR7y0idgCuA+4CuqvN/wH8E0BmnhoRRwL/RmOE0/PApzPz9/2Np25G5kVgckRcSaNGZhfg+og4uQrsk/0NQJIkLZ7uQVLwnpnX88q7APS0z/eB7y+pc9ZtyFzAKyfF+92SCkCSJKm/WjZkImIYsEtmHjwA8UiSpD4aLDUynVDnFgXzgTUiYtkBiEeSJKm2ul1LU4EbIuIi4LkFGxdVkSxJkgbOYKmR6YS6DZkZ1dIFvKZ94UiSJNVXd2bf/2x3IJIkqX+Gco1MrYZMRFwNr/5Xysx3LvGIJEmSaqrbtfTZpsfLA++lMZGNJElSx9TtWrp1oU03RMQ1bYhHkiT1kcW+LUTEyKbVLmBrYK22RCRJklRT3a6lW2nUyAQwl8Zw7MPbFJMkSeqDoVzs23JCvMrngc0zcz3gTBpzycxpW1SSJEk11G3IHJeZs6u7Wu4CTAROaVtUkiSptu7MAVsGm7oNmfnVz3cDp2bmhYC3LJAkSR1Vt0ZmekT8ENgZ+EZELEf9RpAkSWoja2RaOwC4HNg9M2cBI4Fj2hWUJElSHXXnkZkDnN+0PhOY2a6gJElSfZndnQ6hY+wekiRJxapbIyNJkgapbmtkJEmSymNGRpKkwuUgnN9loJiRkSRJxTIjI0lS4ayRkSRJKpANGUmSVCy7liRJKpzFvpIkSQUyIyNJUuG6zchIkiSVx4yMJEmFS4dfS5IklceMjCRJhXPUkiRJUoHMyEiSVDhvUSBJklQgMzKSJBXOGhlJkqQCmZGRJKlwzuwrSZJUIDMykiQVzhoZSZKkAtmQkSRJxbJrSZKkwjkhniRJUoHMyEiSVDiLfSVJkgpkRkaSpMI5IZ4kSVKBzMhIklS4dNSSJElSeczISJJUOGtkJEmSCmRGRpKkwjmPjCRJUoHMyEiSVDhHLUmSJBXIjIwkSYWzRkaSJKlANmQkSVKxbMhIklS4zBywpZWI2D0i7o+IhyLi2B6ej4g4uXr+zojYcnHeuw0ZSZK0RETEMOAHwB7AxsBBEbHxQrvtAWxULeOBUxbnnDZkJEkqXA7g0sI44KHMfDgzXwLOAfZdaJ99gZ9mw03AqhGxdv/euQ0ZSZK05IwBHmtan1Zt6+s+tbV9+PW8l6ZHu8/RSRExPjMndDoO9Y/Xr1xeu7J5/ZasgfyujYjxNLqEFpjQdC17imPhRE6dfWozI7P4xrfeRYOY169cXruyef0KlZkTMnPrpqW5QToNGNu0vg4wY6GXqLNPbTZkJEnSknIzsFFErBcRywLvBy5aaJ+LgA9Xo5e2BZ7JzJn9PaEz+0qSpCUiM+dFxJHA5cAw4PTMnBwRH6uePxWYBOwJPATMAQ5bnHPakFl89vGWzetXLq9d2bx+S6nMnESjsdK87dSmxwkcsaTOF0P5/gySJKls1shIkqRiLdUNmYhYNyLubvM5ft/O11f7Vf9PPtDPY/++pOPRKw3E77EGj4iYFBGrdjoOlWOpbsgMhMx8W6dj0GJbF+ixIRMR1pFJi6Hu71A1gqUrM/fMzFltDktLkaHQkBkWET+KiMkRcUVErBAR/xoRN0fEHRHxq4hYESAiJkbEqRFxXUQ8EBF7VdsPjYgLI+I31Y2wvrTgxRf8RR4RO0bE7yLilxFxX0ScFRFRPbdVRFwTEbdGxOULpmKOiE9GxD3VTbPOqba9IyJur5Y/RcRrBvofrBTVX+r39nB9N6iu1a3VtXxjtf/EiHhf0/ELsiknAm+v/s0/VV3vX0TExcAVEbFSRFwVEbdFxF0RsfB026ohIkZExKXV793dEXFgRBxf/S7eHRETFvqduSMibqSpKLC6NudX1/fBiPhm03O7RsSN1XX6RUSsVG0/sen37L+rbftX57wjIq4d4H+KIi3i+k2NiFHV81tHxO+qx1+urucVwE8X9Rna9Dv8v8BtwNgFr9nT+apjevw81RA2kHfMHOiFxl/a84DNq/XzgIOB1Zv2+SrwierxROA3NBp4G9GYtGd54FBgJrA6sAJwN7B1dczfq587As/QmNinC7gR2AEYDvweWKPa70Aaw9GgMQHQctXjVaufFwPbV49XApbp9L/jYF16ub5XARtV294K/F/T9X1f0/HN1+6Spu2HVtd+ZLW+DLBy9XgUjSGD0fwaLrWu13uBHzWtr7Lg37haPxPYu3p8J/CO6vG3gLubrs3D1bHLA4/SmFhrFHAtMKLa7/PA8cBI4P6m67Vq9fMuYEzzNpd+Xb+pwKhqfWvgd9XjLwO3Ais0XbdXfYZWv8PdwLZNrzu1up49nW+Rn6cuQ3cZChmZRzLz9urxrTR+cTat/lK/C/ggsEnT/udlZndmPkjjA/ON1fYrM/PpzHweOJ9GI2Vhf8zMaZnZDdxenesNwKbAlRFxO3AcjcYOND6sz4qIg2l8IQPcAJwUEZ+k8QE7D/Wmp+v7NuAX1b/3D4H+/MV2ZWb+tXocwNcj4k7gtzTuCbLmYsQ8VN0F7BwR34iIt2fmM8BOEfGH6nfxncAmEbEKjf/711THnbnQ61yVmc9k5gvAPcDrgG1p3Gn3huq6H1Jtnw28APw4It5DY84KaPyeTYyIf6Ux14Va6+n69eai6vNygUV9hj6ajRsH1jlfb5+nGqKGQv//i02P59P4a2AisF9m3hERh9L4i3yBhcejZ4vtvZ1rGRpfgpMzc7se9n838P+AfYAvRsQmmXliRFxKY7KgmyJi58y8bxHvTa/+N18TmJWZm/ew7zyq7tSqC2PZXl73uabHHwTWALbKzLkRMZVGNkB9kJkPRMRWNP5v/1fV7XAEjezmYxHxZRr/rkHv911Z1O/ZlZl50MI7R8Q44F00Zhg9EnhnZn4sIt5K43fw9ojYPDOfXuw3uRRbxPV7+XeKV/9OPLfQ+qI+Qxfer7fzXcCiP081RA2FjExPXgPMjIjhNL6kmu0fEV0RsQGwPo20NMAuETEyIlYA9qPxF10d9wNrRMR2ABExPCI2iYguYGxmXg18DlgVWCkiNsjMuzLzG8At/CMjpHpmA49ExP7wcgHhZtVzU4Gtqsf70khTAzxL4//EoqwCPFk1Ynai8Ze++igiRgNzMvNnwH8DW1ZPPVXVs7wPIBuFns9ExIK/2Bf+He3JTcD2EbFhda4VI+L11euuko0Juo4GNq+e3yAz/5CZxwNP8cr7vqgHi7h+U/nH79R7W7xEnz5DF3G+Hj9P+/eOtLQYChmZnnwR+AON/vW7eOWX2P3ANTT+sv9YZr7Q+OOd62mkuDcEzs7MW+qcKDNfikaB6clVynwZ4DvAA8DPqm0BfDszZ0XEV6ovy/k00uaXLe6bHYI+CJwSEcfRaKycA9wB/Ai4MCL+SKOOZsFfgncC8yLiDhrZur8t9HpnARdHxC00ugzNkPXPm4FvRUQ3MBf4NxpfaHfR+EK8uWnfw4DTI2IOjanOe5WZf6myqz+PiOWqzcfRaKReGBELMj2fqp77VkRsVG27isb/D/Wup+u3AnBaRPwHjc/U3rzqMzQi1u3L+Xr5PJ3c/7el0jmzb5OImEij6POXC20/lEb6+8hOxCVJJfMzVO00VLuWJEnSUsCMjCRJKpYZGUmSVCwbMpIkqVg2ZCRJUrFsyEiSpGLZkJEkScWyISNJkor1/wEo2w+cQNtoPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "heatmap = sns.heatmap(conf, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec979b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5734112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
