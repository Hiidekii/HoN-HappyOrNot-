{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9db5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import face_recognition as fr\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a9ac7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths =[\"data/CK+/\",\"data/fer/train/\"]\n",
    "# data  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs = []\n",
    "state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "355c9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "            state.extend([item for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a6c9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29611, 29611)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state),len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08d0c4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['data/CK+/surprise/S052_001_00000015.png',\n",
       "  'data/CK+/surprise/S050_002_00000018.png',\n",
       "  'data/CK+/surprise/S086_001_00000019.png',\n",
       "  'data/CK+/surprise/S037_001_00000020.png',\n",
       "  'data/CK+/surprise/S034_001_00000029.png'],\n",
       " ['surprise', 'surprise', 'surprise', 'surprise', 'surprise'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[:5],state[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e8c4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ = []\n",
    "for p in imgs:\n",
    "    temp = Image.open(p)\n",
    "    save = temp.copy()\n",
    "    imgs_.append(save)\n",
    "    temp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae8835de",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = []\n",
    "HEIGHT, WIDTH =75,75\n",
    "for f in imgs_:\n",
    "    img = f.convert(\"RGB\").resize((HEIGHT, WIDTH))\n",
    "    imgs_array.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a9634d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_array = [el/255 for el in imgs_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbe5cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = np.array(imgs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6383adcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 75, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05d8ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(set(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43bcc66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'surprise', 'sadness', 'disgust', 'fear', 'neutral', 'happiness']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82e371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b65e3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(state)\n",
    "y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "335e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array,y_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34aa7281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22208, 75, 75, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b5d459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD, Adamax\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e833a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feats = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(75,75,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "958b8f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 75, 75, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_feats.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e00702ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1, 1, 2048)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_feats.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2285352",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Sequential()\n",
    "output.add(Flatten(input_shape=[1,1,2048]))\n",
    "output.add(Dense(64,activation = 'relu'))\n",
    "output.add(Dense(128,activation = 'relu'))\n",
    "output.add(Dense(256,activation = 'relu'))\n",
    "output.add(Dense(512,activation = 'relu'))\n",
    "output.add(Dropout(0.3))\n",
    "output.add(BatchNormalization())\n",
    "output.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9db01d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "751fe068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# #model.add(Flatten())\n",
    "# model.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(imgs_array.shape[1:])))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Conv2D(filters=512, kernel_size=3, activation='relu', input_shape=(imgs_array.shape[1:])))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64,activation = 'relu'))\n",
    "# model.add(Dense(128,activation = 'relu'))\n",
    "# model.add(Dense(256,activation = 'relu'))\n",
    "# model.add(Dense(512,activation = 'relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(7, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24ab861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([model_feats,output])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed763968",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "625/625 [==============================] - 763s 1s/step - loss: 1.7618 - accuracy: 0.3132 - val_loss: 2041.0928 - val_accuracy: 0.1247\n",
      "Epoch 2/5000\n",
      "625/625 [==============================] - 359s 575ms/step - loss: 1.6616 - accuracy: 0.3499 - val_loss: 1.7242 - val_accuracy: 0.3138\n",
      "Epoch 3/5000\n",
      "625/625 [==============================] - 196s 314ms/step - loss: 1.5759 - accuracy: 0.3835 - val_loss: 1.5327 - val_accuracy: 0.3908\n",
      "Epoch 4/5000\n",
      "625/625 [==============================] - 118s 189ms/step - loss: 1.4693 - accuracy: 0.4273 - val_loss: 1.6381 - val_accuracy: 0.4728\n",
      "Epoch 5/5000\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 1.3818 - accuracy: 0.4658 - val_loss: 16.2984 - val_accuracy: 0.4093\n",
      "Epoch 6/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 1.3644 - accuracy: 0.4773 - val_loss: 1.5724 - val_accuracy: 0.4746\n",
      "Epoch 7/5000\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 1.3793 - accuracy: 0.4671 - val_loss: 1.6505 - val_accuracy: 0.4561\n",
      "Epoch 8/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.3901 - accuracy: 0.4705 - val_loss: 1.4118 - val_accuracy: 0.4484\n",
      "Epoch 9/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.4561 - accuracy: 0.4373 - val_loss: 1.5306 - val_accuracy: 0.4156\n",
      "Epoch 10/5000\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 1.3826 - accuracy: 0.4761 - val_loss: 1.3839 - val_accuracy: 0.4669\n",
      "Epoch 11/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.3693 - accuracy: 0.4795 - val_loss: 1.3076 - val_accuracy: 0.4975\n",
      "Epoch 12/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.3355 - accuracy: 0.4932 - val_loss: 43.0697 - val_accuracy: 0.3944\n",
      "Epoch 13/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 1.2869 - accuracy: 0.5141 - val_loss: 1.2793 - val_accuracy: 0.5218\n",
      "Epoch 14/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 1.3768 - accuracy: 0.4807 - val_loss: 1.3326 - val_accuracy: 0.4849\n",
      "Epoch 15/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.2251 - accuracy: 0.5396 - val_loss: 1.3840 - val_accuracy: 0.4867\n",
      "Epoch 16/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.4440 - accuracy: 0.4529 - val_loss: 1.5798 - val_accuracy: 0.4102\n",
      "Epoch 17/5000\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 1.3300 - accuracy: 0.4992 - val_loss: 1.7033 - val_accuracy: 0.4138\n",
      "Epoch 18/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 1.3310 - accuracy: 0.5011 - val_loss: 1.3445 - val_accuracy: 0.4822\n",
      "Epoch 19/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 1.3671 - accuracy: 0.4788 - val_loss: 1.3090 - val_accuracy: 0.4948\n",
      "Epoch 20/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 1.2456 - accuracy: 0.5314 - val_loss: 1.4020 - val_accuracy: 0.4498\n",
      "Epoch 21/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.1985 - accuracy: 0.5543 - val_loss: 1.2063 - val_accuracy: 0.5344\n",
      "Epoch 22/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 1.1318 - accuracy: 0.5831 - val_loss: 1.2012 - val_accuracy: 0.5299\n",
      "Epoch 23/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 1.0889 - accuracy: 0.5972 - val_loss: 1.1916 - val_accuracy: 0.5376\n",
      "Epoch 24/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 1.0427 - accuracy: 0.6161 - val_loss: 1.3459 - val_accuracy: 0.5119\n",
      "Epoch 25/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.0205 - accuracy: 0.6255 - val_loss: 1.2798 - val_accuracy: 0.5281\n",
      "Epoch 26/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.9749 - accuracy: 0.6421 - val_loss: 1.1889 - val_accuracy: 0.5358\n",
      "Epoch 27/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.9699 - accuracy: 0.6431 - val_loss: 1.3598 - val_accuracy: 0.5236\n",
      "Epoch 28/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.8702 - accuracy: 0.6823 - val_loss: 1.1908 - val_accuracy: 0.5525\n",
      "Epoch 29/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.8241 - accuracy: 0.6984 - val_loss: 1.3022 - val_accuracy: 0.5286\n",
      "Epoch 30/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.7678 - accuracy: 0.7238 - val_loss: 1.3348 - val_accuracy: 0.5669\n",
      "Epoch 31/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.7280 - accuracy: 0.7348 - val_loss: 1.3695 - val_accuracy: 0.5263\n",
      "Epoch 32/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.8219 - accuracy: 0.7051 - val_loss: 1.2229 - val_accuracy: 0.5727\n",
      "Epoch 33/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.6924 - accuracy: 0.7523 - val_loss: 1.2716 - val_accuracy: 0.5615\n",
      "Epoch 34/5000\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.6336 - accuracy: 0.7758 - val_loss: 1.2760 - val_accuracy: 0.5642\n",
      "Epoch 35/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.5602 - accuracy: 0.8046 - val_loss: 1.4488 - val_accuracy: 0.5520\n",
      "Epoch 36/5000\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.6188 - accuracy: 0.7888 - val_loss: 1.4758 - val_accuracy: 0.5065\n",
      "Epoch 37/5000\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 0.4975 - accuracy: 0.8277 - val_loss: 1.4187 - val_accuracy: 0.5817\n",
      "Epoch 38/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.4625 - accuracy: 0.8430 - val_loss: 1.4769 - val_accuracy: 0.5772\n",
      "Epoch 39/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.3679 - accuracy: 0.8798 - val_loss: 1.5708 - val_accuracy: 0.5808\n",
      "Epoch 40/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.3402 - accuracy: 0.8881 - val_loss: 1.6168 - val_accuracy: 0.5696\n",
      "Epoch 41/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.3209 - accuracy: 0.8970 - val_loss: 1.5710 - val_accuracy: 0.5835\n",
      "Epoch 42/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.2819 - accuracy: 0.9090 - val_loss: 1.6802 - val_accuracy: 0.5705\n",
      "Epoch 43/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.2677 - accuracy: 0.9153 - val_loss: 1.6742 - val_accuracy: 0.5624\n",
      "Epoch 44/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.2299 - accuracy: 0.9263 - val_loss: 1.7358 - val_accuracy: 0.5750\n",
      "Epoch 45/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.2153 - accuracy: 0.9306 - val_loss: 1.7722 - val_accuracy: 0.5664\n",
      "Epoch 46/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.2061 - accuracy: 0.9344 - val_loss: 1.7919 - val_accuracy: 0.5624\n",
      "Epoch 47/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.2069 - accuracy: 0.9373 - val_loss: 1.7962 - val_accuracy: 0.5660\n",
      "Epoch 48/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.1746 - accuracy: 0.9451 - val_loss: 1.9322 - val_accuracy: 0.5642\n",
      "Epoch 49/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.1623 - accuracy: 0.9488 - val_loss: 1.8502 - val_accuracy: 0.5835\n",
      "Epoch 50/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.1725 - accuracy: 0.9464 - val_loss: 1.9010 - val_accuracy: 0.5691\n",
      "Epoch 51/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.1580 - accuracy: 0.9509 - val_loss: 1.7856 - val_accuracy: 0.5907\n",
      "Epoch 52/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.1320 - accuracy: 0.9592 - val_loss: 1.9128 - val_accuracy: 0.5813\n",
      "Epoch 53/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.1487 - accuracy: 0.9538 - val_loss: 1.9054 - val_accuracy: 0.5637\n",
      "Epoch 54/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.1193 - accuracy: 0.9640 - val_loss: 2.0200 - val_accuracy: 0.5687\n",
      "Epoch 55/5000\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 0.1226 - accuracy: 0.9615 - val_loss: 2.0846 - val_accuracy: 0.5718\n",
      "Epoch 56/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.1621 - accuracy: 0.9513 - val_loss: 1.8797 - val_accuracy: 0.5511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.1726 - accuracy: 0.9462 - val_loss: 2.0023 - val_accuracy: 0.5727\n",
      "Epoch 58/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0950 - accuracy: 0.9731 - val_loss: 1.9636 - val_accuracy: 0.5777\n",
      "Epoch 59/5000\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.1127 - accuracy: 0.9660 - val_loss: 2.0941 - val_accuracy: 0.5741\n",
      "Epoch 60/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0884 - accuracy: 0.9760 - val_loss: 2.0662 - val_accuracy: 0.5849\n",
      "Epoch 61/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.1086 - accuracy: 0.9678 - val_loss: 2.0409 - val_accuracy: 0.5817\n",
      "Epoch 62/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.1085 - accuracy: 0.9678 - val_loss: 2.0864 - val_accuracy: 0.5682\n",
      "Epoch 63/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0884 - accuracy: 0.9733 - val_loss: 2.0524 - val_accuracy: 0.5696\n",
      "Epoch 64/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0937 - accuracy: 0.9726 - val_loss: 2.1792 - val_accuracy: 0.5727\n",
      "Epoch 65/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.2550 - accuracy: 0.9222 - val_loss: 1.8378 - val_accuracy: 0.5727\n",
      "Epoch 66/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0835 - accuracy: 0.9753 - val_loss: 2.1483 - val_accuracy: 0.5894\n",
      "Epoch 67/5000\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.0584 - accuracy: 0.9831 - val_loss: 2.2505 - val_accuracy: 0.5795\n",
      "Epoch 68/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0843 - accuracy: 0.9752 - val_loss: 2.2699 - val_accuracy: 0.5804\n",
      "Epoch 69/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0751 - accuracy: 0.9788 - val_loss: 2.1144 - val_accuracy: 0.5822\n",
      "Epoch 70/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0747 - accuracy: 0.9763 - val_loss: 2.1641 - val_accuracy: 0.5795\n",
      "Epoch 71/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0751 - accuracy: 0.9776 - val_loss: 2.1535 - val_accuracy: 0.5777\n",
      "Epoch 72/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0652 - accuracy: 0.9817 - val_loss: 2.1579 - val_accuracy: 0.5759\n",
      "Epoch 73/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0891 - accuracy: 0.9743 - val_loss: 1.9849 - val_accuracy: 0.5844\n",
      "Epoch 74/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0615 - accuracy: 0.9822 - val_loss: 2.1547 - val_accuracy: 0.5907\n",
      "Epoch 75/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0729 - accuracy: 0.9784 - val_loss: 2.0552 - val_accuracy: 0.5579\n",
      "Epoch 76/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0696 - accuracy: 0.9791 - val_loss: 2.0773 - val_accuracy: 0.5903\n",
      "Epoch 77/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0654 - accuracy: 0.9812 - val_loss: 2.1970 - val_accuracy: 0.5808\n",
      "Epoch 78/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0746 - accuracy: 0.9784 - val_loss: 1.9322 - val_accuracy: 0.5889\n",
      "Epoch 79/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 2.2010 - val_accuracy: 0.5696\n",
      "Epoch 80/5000\n",
      "625/625 [==============================] - 28s 44ms/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 2.0278 - val_accuracy: 0.5916\n",
      "Epoch 81/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.1102 - accuracy: 0.9661 - val_loss: 1.9516 - val_accuracy: 0.5907\n",
      "Epoch 82/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0564 - accuracy: 0.9834 - val_loss: 2.0811 - val_accuracy: 0.5921\n",
      "Epoch 83/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0488 - accuracy: 0.9873 - val_loss: 2.0899 - val_accuracy: 0.6033\n",
      "Epoch 84/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0512 - accuracy: 0.9854 - val_loss: 2.1084 - val_accuracy: 0.5205\n",
      "Epoch 85/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0784 - accuracy: 0.9766 - val_loss: 2.1390 - val_accuracy: 0.5957\n",
      "Epoch 86/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0504 - accuracy: 0.9841 - val_loss: 2.1173 - val_accuracy: 0.5948\n",
      "Epoch 87/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 2.0185 - val_accuracy: 0.5858\n",
      "Epoch 88/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0469 - accuracy: 0.9861 - val_loss: 2.2552 - val_accuracy: 0.5498\n",
      "Epoch 89/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0581 - accuracy: 0.9826 - val_loss: 2.1836 - val_accuracy: 0.5880\n",
      "Epoch 90/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 2.1824 - val_accuracy: 0.5966\n",
      "Epoch 91/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0528 - accuracy: 0.9846 - val_loss: 2.1247 - val_accuracy: 0.5930\n",
      "Epoch 92/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0632 - accuracy: 0.9821 - val_loss: 2.1505 - val_accuracy: 0.5826\n",
      "Epoch 93/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0564 - accuracy: 0.9837 - val_loss: 2.1161 - val_accuracy: 0.5727\n",
      "Epoch 94/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 2.2678 - val_accuracy: 0.5934\n",
      "Epoch 95/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 2.1851 - val_accuracy: 0.5876\n",
      "Epoch 96/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0644 - accuracy: 0.9817 - val_loss: 2.0876 - val_accuracy: 0.5831\n",
      "Epoch 97/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0497 - accuracy: 0.9856 - val_loss: 2.1657 - val_accuracy: 0.5934\n",
      "Epoch 98/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0428 - accuracy: 0.9870 - val_loss: 2.0755 - val_accuracy: 0.5916\n",
      "Epoch 99/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 2.2127 - val_accuracy: 0.5957\n",
      "Epoch 100/5000\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.0534 - accuracy: 0.9830 - val_loss: 2.2250 - val_accuracy: 0.5948\n",
      "Epoch 101/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 2.0337 - val_accuracy: 0.5777\n",
      "Epoch 102/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0434 - accuracy: 0.9870 - val_loss: 2.2796 - val_accuracy: 0.5858\n",
      "Epoch 103/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 2.2190 - val_accuracy: 0.5754\n",
      "Epoch 104/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0427 - accuracy: 0.9870 - val_loss: 2.0791 - val_accuracy: 0.5903\n",
      "Epoch 105/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 1.9713 - val_accuracy: 0.5799\n",
      "Epoch 106/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 2.3522 - val_accuracy: 0.5934\n",
      "Epoch 107/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0351 - accuracy: 0.9886 - val_loss: 2.2541 - val_accuracy: 0.6033\n",
      "Epoch 108/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 2.1237 - val_accuracy: 0.5939\n",
      "Epoch 109/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0292 - accuracy: 0.9910 - val_loss: 2.2991 - val_accuracy: 0.5853\n",
      "Epoch 110/5000\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 2.1468 - val_accuracy: 0.5912\n",
      "Epoch 111/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0531 - accuracy: 0.9839 - val_loss: 2.0895 - val_accuracy: 0.5961\n",
      "Epoch 112/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0443 - accuracy: 0.9876 - val_loss: 2.0672 - val_accuracy: 0.5898\n",
      "Epoch 113/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 2.3485 - val_accuracy: 0.5907\n",
      "Epoch 114/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 2.0884 - val_accuracy: 0.5835\n",
      "Epoch 115/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 2.3589 - val_accuracy: 0.5907\n",
      "Epoch 116/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 2.1968 - val_accuracy: 0.6029\n",
      "Epoch 117/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0290 - accuracy: 0.9919 - val_loss: 2.1878 - val_accuracy: 0.5912\n",
      "Epoch 118/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 2.2105 - val_accuracy: 0.5970\n",
      "Epoch 119/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 2.2646 - val_accuracy: 0.5862\n",
      "Epoch 120/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0574 - accuracy: 0.9828 - val_loss: 2.1178 - val_accuracy: 0.5934\n",
      "Epoch 121/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 2.3148 - val_accuracy: 0.5979\n",
      "Epoch 122/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0380 - accuracy: 0.9883 - val_loss: 2.1479 - val_accuracy: 0.6020\n",
      "Epoch 123/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 2.4476 - val_accuracy: 0.5844\n",
      "Epoch 124/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 2.2876 - val_accuracy: 0.5840\n",
      "Epoch 125/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0336 - accuracy: 0.9907 - val_loss: 2.2858 - val_accuracy: 0.5948\n",
      "Epoch 126/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 2.3051 - val_accuracy: 0.5934\n",
      "Epoch 127/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 2.2082 - val_accuracy: 0.5894\n",
      "Epoch 128/5000\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 0.0805 - accuracy: 0.9748 - val_loss: 2.1099 - val_accuracy: 0.5939\n",
      "Epoch 129/5000\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 2.2268 - val_accuracy: 0.5925\n",
      "Epoch 130/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 2.4527 - val_accuracy: 0.6020\n",
      "Epoch 131/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 2.4293 - val_accuracy: 0.5957\n",
      "Epoch 132/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 2.3826 - val_accuracy: 0.5966\n",
      "Epoch 133/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 2.3343 - val_accuracy: 0.5993\n",
      "Epoch 134/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 2.3595 - val_accuracy: 0.5750\n",
      "Epoch 135/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 2.4337 - val_accuracy: 0.5831\n",
      "Epoch 136/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 2.1831 - val_accuracy: 0.5835\n",
      "Epoch 137/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 2.1824 - val_accuracy: 0.5745\n",
      "Epoch 138/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 2.2602 - val_accuracy: 0.6002\n",
      "Epoch 139/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 2.2975 - val_accuracy: 0.5894\n",
      "Epoch 140/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 2.2739 - val_accuracy: 0.5831\n",
      "Epoch 141/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 2.2073 - val_accuracy: 0.5961\n",
      "Epoch 142/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 2.2817 - val_accuracy: 0.6101\n",
      "Epoch 143/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 2.4189 - val_accuracy: 0.5894\n",
      "Epoch 144/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 2.2745 - val_accuracy: 0.5763\n",
      "Epoch 145/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 2.1757 - val_accuracy: 0.5916\n",
      "Epoch 146/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 2.3745 - val_accuracy: 0.6002\n",
      "Epoch 147/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0298 - accuracy: 0.9910 - val_loss: 2.2286 - val_accuracy: 0.5844\n",
      "Epoch 148/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 2.3062 - val_accuracy: 0.5961\n",
      "Epoch 149/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 2.2184 - val_accuracy: 0.5840\n",
      "Epoch 150/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 2.1671 - val_accuracy: 0.5831\n",
      "Epoch 151/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 2.1370 - val_accuracy: 0.5993\n",
      "Epoch 152/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 2.3628 - val_accuracy: 0.5777\n",
      "Epoch 153/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 2.2420 - val_accuracy: 0.5957\n",
      "Epoch 154/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0270 - accuracy: 0.9919 - val_loss: 2.3614 - val_accuracy: 0.6029\n",
      "Epoch 155/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 2.1884 - val_accuracy: 0.5799\n",
      "Epoch 156/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 2.2698 - val_accuracy: 0.5948\n",
      "Epoch 157/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 2.4234 - val_accuracy: 0.5916\n",
      "Epoch 158/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 2.2968 - val_accuracy: 0.5795\n",
      "Epoch 159/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 2.2186 - val_accuracy: 0.5763\n",
      "Epoch 160/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 2.2337 - val_accuracy: 0.5903\n",
      "Epoch 161/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 2.3403 - val_accuracy: 0.5889\n",
      "Epoch 162/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 2.0861 - val_accuracy: 0.5984\n",
      "Epoch 163/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 2.2902 - val_accuracy: 0.5894\n",
      "Epoch 164/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 2.1927 - val_accuracy: 0.5885\n",
      "Epoch 165/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 2.2515 - val_accuracy: 0.6002\n",
      "Epoch 166/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 2.1973 - val_accuracy: 0.5880\n",
      "Epoch 167/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 2.1371 - val_accuracy: 0.6074\n",
      "Epoch 168/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 2.1893 - val_accuracy: 0.5849\n",
      "Epoch 169/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 2.2684 - val_accuracy: 0.6006\n",
      "Epoch 170/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 2.0016 - val_accuracy: 0.6060\n",
      "Epoch 171/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 2.2835 - val_accuracy: 0.5952\n",
      "Epoch 172/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0272 - accuracy: 0.9918 - val_loss: 2.1607 - val_accuracy: 0.5988\n",
      "Epoch 173/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 2.2609 - val_accuracy: 0.5993\n",
      "Epoch 174/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 2.2725 - val_accuracy: 0.5808\n",
      "Epoch 175/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 2.0607 - val_accuracy: 0.6024\n",
      "Epoch 176/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 2.2096 - val_accuracy: 0.5889\n",
      "Epoch 177/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 2.4350 - val_accuracy: 0.5907\n",
      "Epoch 178/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 2.3232 - val_accuracy: 0.5862\n",
      "Epoch 179/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 2.1953 - val_accuracy: 0.5921\n",
      "Epoch 180/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 2.1286 - val_accuracy: 0.5975\n",
      "Epoch 181/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 2.2834 - val_accuracy: 0.5826\n",
      "Epoch 182/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0245 - accuracy: 0.9929 - val_loss: 2.3317 - val_accuracy: 0.6011\n",
      "Epoch 183/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 2.3639 - val_accuracy: 0.5916\n",
      "Epoch 184/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 2.1763 - val_accuracy: 0.5894\n",
      "Epoch 185/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 2.3888 - val_accuracy: 0.6078\n",
      "Epoch 186/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 2.1983 - val_accuracy: 0.5916\n",
      "Epoch 187/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 2.3867 - val_accuracy: 0.5939\n",
      "Epoch 188/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0257 - accuracy: 0.9928 - val_loss: 2.1862 - val_accuracy: 0.5804\n",
      "Epoch 189/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 2.3544 - val_accuracy: 0.5858\n",
      "Epoch 190/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 2.3041 - val_accuracy: 0.5921\n",
      "Epoch 191/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 2.4910 - val_accuracy: 0.5889\n",
      "Epoch 192/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 2.5067 - val_accuracy: 0.5934\n",
      "Epoch 193/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0311 - accuracy: 0.9907 - val_loss: 2.2483 - val_accuracy: 0.5727\n",
      "Epoch 194/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0487 - accuracy: 0.9859 - val_loss: 2.0831 - val_accuracy: 0.6011\n",
      "Epoch 195/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 2.3463 - val_accuracy: 0.5957\n",
      "Epoch 196/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 2.3493 - val_accuracy: 0.5997\n",
      "Epoch 197/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 2.3447 - val_accuracy: 0.6011\n",
      "Epoch 198/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 2.2182 - val_accuracy: 0.5948\n",
      "Epoch 199/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 2.2645 - val_accuracy: 0.5943\n",
      "Epoch 200/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 2.2989 - val_accuracy: 0.5943\n",
      "Epoch 201/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 2.3208 - val_accuracy: 0.6024\n",
      "Epoch 202/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 2.5485 - val_accuracy: 0.5741\n",
      "Epoch 203/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 2.2716 - val_accuracy: 0.5849\n",
      "Epoch 204/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 2.2905 - val_accuracy: 0.5916\n",
      "Epoch 205/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 2.4106 - val_accuracy: 0.6069\n",
      "Epoch 206/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 2.4414 - val_accuracy: 0.5849\n",
      "Epoch 207/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 2.2787 - val_accuracy: 0.6006\n",
      "Epoch 208/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 2.3237 - val_accuracy: 0.5939\n",
      "Epoch 209/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 2.5046 - val_accuracy: 0.5871\n",
      "Epoch 210/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 2.3381 - val_accuracy: 0.5966\n",
      "Epoch 211/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 2.2825 - val_accuracy: 0.6029\n",
      "Epoch 212/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 2.1399 - val_accuracy: 0.5997\n",
      "Epoch 213/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 2.4366 - val_accuracy: 0.5840\n",
      "Epoch 214/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 2.2672 - val_accuracy: 0.5799\n",
      "Epoch 215/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 2.4799 - val_accuracy: 0.5925\n",
      "Epoch 216/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 2.3460 - val_accuracy: 0.5930\n",
      "Epoch 217/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 2.2318 - val_accuracy: 0.6033\n",
      "Epoch 218/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 2.4387 - val_accuracy: 0.5970\n",
      "Epoch 219/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 2.2852 - val_accuracy: 0.5862\n",
      "Epoch 220/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 2.2427 - val_accuracy: 0.5916\n",
      "Epoch 221/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 2.3159 - val_accuracy: 0.6024\n",
      "Epoch 222/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 2.3109 - val_accuracy: 0.6011\n",
      "Epoch 223/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 2.4370 - val_accuracy: 0.6078\n",
      "Epoch 224/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 2.3438 - val_accuracy: 0.5961\n",
      "Epoch 225/5000\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 2.2397 - val_accuracy: 0.5952\n",
      "Epoch 226/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 2.2641 - val_accuracy: 0.5876\n",
      "Epoch 227/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 2.2814 - val_accuracy: 0.5889\n",
      "Epoch 228/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 2.3177 - val_accuracy: 0.5948\n",
      "Epoch 229/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 2.2113 - val_accuracy: 0.6011\n",
      "Epoch 230/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 2.2626 - val_accuracy: 0.5925\n",
      "Epoch 231/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 2.4190 - val_accuracy: 0.5984\n",
      "Epoch 232/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 2.1840 - val_accuracy: 0.6083\n",
      "Epoch 233/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 2.3556 - val_accuracy: 0.6096\n",
      "Epoch 234/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 2.4020 - val_accuracy: 0.5975\n",
      "Epoch 235/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 2.2305 - val_accuracy: 0.6015\n",
      "Epoch 236/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 2.3389 - val_accuracy: 0.5903\n",
      "Epoch 237/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 2.4436 - val_accuracy: 0.5907\n",
      "Epoch 238/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 2.3279 - val_accuracy: 0.5993\n",
      "Epoch 239/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 2.3524 - val_accuracy: 0.6033\n",
      "Epoch 240/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 2.3784 - val_accuracy: 0.6042\n",
      "Epoch 241/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 2.2207 - val_accuracy: 0.5952\n",
      "Epoch 242/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 2.3174 - val_accuracy: 0.6060\n",
      "Epoch 243/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 2.1855 - val_accuracy: 0.6042\n",
      "Epoch 244/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 2.3191 - val_accuracy: 0.6119\n",
      "Epoch 245/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 2.2130 - val_accuracy: 0.6078\n",
      "Epoch 246/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 2.3373 - val_accuracy: 0.6060\n",
      "Epoch 247/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 2.3724 - val_accuracy: 0.6101\n",
      "Epoch 248/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 2.3340 - val_accuracy: 0.6011\n",
      "Epoch 249/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 2.3359 - val_accuracy: 0.6006\n",
      "Epoch 250/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 2.2418 - val_accuracy: 0.6015\n",
      "Epoch 251/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 2.2708 - val_accuracy: 0.5988\n",
      "Epoch 252/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 2.2930 - val_accuracy: 0.6114\n",
      "Epoch 253/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 2.2560 - val_accuracy: 0.6092\n",
      "Epoch 254/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 2.1790 - val_accuracy: 0.6096\n",
      "Epoch 255/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 2.3606 - val_accuracy: 0.6168\n",
      "Epoch 256/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 2.2660 - val_accuracy: 0.6002\n",
      "Epoch 257/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 2.3553 - val_accuracy: 0.5903\n",
      "Epoch 258/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 2.2887 - val_accuracy: 0.6024\n",
      "Epoch 259/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 2.2680 - val_accuracy: 0.5903\n",
      "Epoch 260/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 2.3712 - val_accuracy: 0.5939\n",
      "Epoch 261/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 2.5450 - val_accuracy: 0.6078\n",
      "Epoch 262/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 2.2430 - val_accuracy: 0.6083\n",
      "Epoch 263/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 2.2767 - val_accuracy: 0.6038\n",
      "Epoch 264/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 2.3277 - val_accuracy: 0.6101\n",
      "Epoch 265/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 2.4242 - val_accuracy: 0.5925\n",
      "Epoch 266/5000\n",
      "625/625 [==============================] - 28s 44ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 2.3096 - val_accuracy: 0.6096\n",
      "Epoch 267/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 2.2314 - val_accuracy: 0.6033\n",
      "Epoch 268/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 2.3651 - val_accuracy: 0.5948\n",
      "Epoch 269/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 2.1955 - val_accuracy: 0.5822\n",
      "Epoch 270/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 2.4008 - val_accuracy: 0.5979\n",
      "Epoch 271/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 2.3994 - val_accuracy: 0.5988\n",
      "Epoch 272/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 2.3947 - val_accuracy: 0.6020\n",
      "Epoch 273/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 2.2676 - val_accuracy: 0.6033\n",
      "Epoch 274/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 2.3741 - val_accuracy: 0.6137\n",
      "Epoch 275/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 2.4028 - val_accuracy: 0.6074\n",
      "Epoch 276/5000\n",
      "625/625 [==============================] - 28s 44ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 2.3589 - val_accuracy: 0.5952\n",
      "Epoch 277/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 2.3869 - val_accuracy: 0.5952\n",
      "Epoch 278/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 2.4074 - val_accuracy: 0.5975\n",
      "Epoch 279/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 2.4876 - val_accuracy: 0.5822\n",
      "Epoch 280/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 2.4580 - val_accuracy: 0.5925\n",
      "Epoch 281/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 2.4668 - val_accuracy: 0.6087\n",
      "Epoch 282/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 2.2999 - val_accuracy: 0.5943\n",
      "Epoch 283/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 2.3946 - val_accuracy: 0.6024\n",
      "Epoch 284/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 2.5007 - val_accuracy: 0.6047\n",
      "Epoch 285/5000\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 2.2713 - val_accuracy: 0.6002\n",
      "Epoch 286/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 2.3802 - val_accuracy: 0.5912\n",
      "Epoch 287/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 2.3711 - val_accuracy: 0.5934\n",
      "Epoch 288/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 2.4239 - val_accuracy: 0.5979\n",
      "Epoch 289/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 2.3290 - val_accuracy: 0.6123\n",
      "Epoch 290/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 2.4868 - val_accuracy: 0.5979\n",
      "Epoch 291/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 2.2992 - val_accuracy: 0.5921\n",
      "Epoch 292/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 2.3711 - val_accuracy: 0.5979\n",
      "Epoch 293/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 2.3921 - val_accuracy: 0.5853\n",
      "Epoch 294/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 2.4455 - val_accuracy: 0.5984\n",
      "Epoch 295/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 2.3900 - val_accuracy: 0.6029\n",
      "Epoch 296/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 2.5709 - val_accuracy: 0.6002\n",
      "Epoch 297/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 2.3162 - val_accuracy: 0.6092\n",
      "Epoch 298/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 2.2089 - val_accuracy: 0.5885\n",
      "Epoch 299/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 2.4442 - val_accuracy: 0.5975\n",
      "Epoch 300/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 2.3644 - val_accuracy: 0.5858\n",
      "Epoch 301/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 2.6408 - val_accuracy: 0.5817\n",
      "Epoch 302/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 2.4724 - val_accuracy: 0.5912\n",
      "Epoch 303/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 2.5576 - val_accuracy: 0.5867\n",
      "Epoch 304/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 2.3511 - val_accuracy: 0.5921\n",
      "Epoch 305/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 2.4733 - val_accuracy: 0.5943\n",
      "Epoch 306/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 2.2139 - val_accuracy: 0.5907\n",
      "Epoch 307/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 2.3579 - val_accuracy: 0.5916\n",
      "Epoch 308/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 2.3895 - val_accuracy: 0.5921\n",
      "Epoch 309/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 2.4667 - val_accuracy: 0.5754\n",
      "Epoch 310/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 2.3641 - val_accuracy: 0.5916\n",
      "Epoch 311/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 2.4345 - val_accuracy: 0.5862\n",
      "Epoch 312/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 2.5206 - val_accuracy: 0.5867\n",
      "Epoch 313/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 2.5085 - val_accuracy: 0.5984\n",
      "Epoch 314/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 2.5237 - val_accuracy: 0.5741\n",
      "Epoch 315/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 2.7811 - val_accuracy: 0.5925\n",
      "Epoch 316/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 2.7493 - val_accuracy: 0.5894\n",
      "Epoch 317/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 2.4236 - val_accuracy: 0.5889\n",
      "Epoch 318/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 2.4738 - val_accuracy: 0.5894\n",
      "Epoch 319/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 2.4901 - val_accuracy: 0.5925\n",
      "Epoch 320/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0077 - accuracy: 0.9969 - val_loss: 2.6213 - val_accuracy: 0.5934\n",
      "Epoch 321/5000\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 2.5891 - val_accuracy: 0.5813\n",
      "Epoch 322/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 2.3995 - val_accuracy: 0.6033\n",
      "Epoch 323/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 2.5565 - val_accuracy: 0.5750\n",
      "Epoch 324/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 2.5895 - val_accuracy: 0.5912\n",
      "Epoch 325/5000\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 2.3356 - val_accuracy: 0.5894\n",
      "Epoch 326/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 2.4264 - val_accuracy: 0.6024\n",
      "Epoch 327/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 2.6567 - val_accuracy: 0.5871\n",
      "Epoch 328/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 2.6398 - val_accuracy: 0.5714\n",
      "Epoch 329/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 2.4746 - val_accuracy: 0.5858\n",
      "Epoch 330/5000\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 2.3982 - val_accuracy: 0.5894\n",
      "Epoch 331/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 2.3141 - val_accuracy: 0.5844\n",
      "Epoch 332/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 25s 39ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 2.3684 - val_accuracy: 0.5912\n",
      "Epoch 333/5000\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.0068 - accuracy: 0.9971 - val_loss: 2.6645 - val_accuracy: 0.5939\n",
      "Epoch 334/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 2.5461 - val_accuracy: 0.5768\n",
      "Epoch 335/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 2.4596 - val_accuracy: 0.5961\n",
      "Epoch 336/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 2.6266 - val_accuracy: 0.5948\n",
      "Epoch 337/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 2.3277 - val_accuracy: 0.6029\n",
      "Epoch 338/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 2.3575 - val_accuracy: 0.5934\n",
      "Epoch 339/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 2.5310 - val_accuracy: 0.5925\n",
      "Epoch 340/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 2.5098 - val_accuracy: 0.5844\n",
      "Epoch 341/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 2.4912 - val_accuracy: 0.5903\n",
      "Epoch 342/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 2.3424 - val_accuracy: 0.5880\n",
      "Epoch 343/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 2.4068 - val_accuracy: 0.5930\n",
      "Epoch 344/5000\n",
      "625/625 [==============================] - 27s 42ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 2.4844 - val_accuracy: 0.5952\n",
      "Epoch 345/5000\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 2.4338 - val_accuracy: 0.5840\n",
      "Epoch 346/5000\n",
      "625/625 [==============================] - 29s 46ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 2.4218 - val_accuracy: 0.5898\n",
      "Epoch 347/5000\n",
      "625/625 [==============================] - 29s 46ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 2.5921 - val_accuracy: 0.5822\n",
      "Epoch 348/5000\n",
      "625/625 [==============================] - 29s 46ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 2.4155 - val_accuracy: 0.5979\n",
      "Epoch 349/5000\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 2.5092 - val_accuracy: 0.5988\n",
      "Epoch 350/5000\n",
      "625/625 [==============================] - 28s 44ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 2.3652 - val_accuracy: 0.5939\n",
      "Epoch 351/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 2.2531 - val_accuracy: 0.5961\n",
      "Epoch 352/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 2.2752 - val_accuracy: 0.6020\n",
      "Epoch 353/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 2.5087 - val_accuracy: 0.6038\n",
      "Epoch 354/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 2.5594 - val_accuracy: 0.5925\n",
      "Epoch 355/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 2.2567 - val_accuracy: 0.6002\n",
      "Epoch 356/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 2.2318 - val_accuracy: 0.6065\n",
      "Epoch 357/5000\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 2.4188 - val_accuracy: 0.5934\n",
      "Epoch 358/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 2.4795 - val_accuracy: 0.5925\n",
      "Epoch 359/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 2.4212 - val_accuracy: 0.5943\n",
      "Epoch 360/5000\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 2.3939 - val_accuracy: 0.6015\n",
      "Epoch 361/5000\n",
      " 69/625 [==>...........................] - ETA: 22s - loss: 0.0176 - accuracy: 0.9959"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4713/1955521547.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras import callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "\n",
    "fecha=str(date.today().year)+str(date.today().month)+str(date.today().day)    \n",
    "symbol = 'faces_iception_2'\n",
    "h5 = symbol + '_best_model' + fecha + '.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                       monitor='loss',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True,\n",
    "                                       #save_weights_only=True,\n",
    "                                       mode='auto',\n",
    "                                       save_freq=1)\n",
    "callback = [checkpoint]\n",
    "json = symbol + '_best_model' + fecha + '.json'\n",
    "model_json = model.to_json()\n",
    "with open(json, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "modelo = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 5000,callbacks = callback,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dbceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/predict/\"] #[\"data/predict/\",\"data/fer/test/\"]\n",
    "# data_pred  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs_pred = []\n",
    "state_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b355f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs_pred.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "            state_pred.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31d91a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/predict/surprise/1636579058672.jpg',\n",
       " 'data/predict/surprise/1636579058703.jpg',\n",
       " 'data/predict/surprise/1636579058689.jpg',\n",
       " 'data/predict/anger/1636579058658.jpg',\n",
       " 'data/predict/anger/1636579058692.jpg',\n",
       " 'data/predict/neutral/neutral_2.jpg',\n",
       " 'data/predict/neutral/neutral_3.jpg',\n",
       " 'data/predict/neutral/1636579058676.jpg',\n",
       " 'data/predict/neutral/neutral_0.jpg',\n",
       " 'data/predict/neutral/1636579058682.jpg',\n",
       " 'data/predict/neutral/1636579058712.jpg',\n",
       " 'data/predict/neutral/neutral_1.jpg',\n",
       " 'data/predict/neutral/neutral_4.jpg',\n",
       " 'data/predict/happiness/happy_6.png',\n",
       " 'data/predict/happiness/happy_8.png',\n",
       " 'data/predict/happiness/1636579058696.jpg',\n",
       " 'data/predict/happiness/happy_4.png',\n",
       " 'data/predict/happiness/happy_10.png',\n",
       " 'data/predict/happiness/happy_11.png',\n",
       " 'data/predict/happiness/1636579058663.jpg',\n",
       " 'data/predict/happiness/1636579058717.jpg',\n",
       " 'data/predict/happiness/happy_3.jpeg',\n",
       " 'data/predict/happiness/happy_14.jpg',\n",
       " 'data/predict/happiness/happy_9.png',\n",
       " 'data/predict/happiness/happy_2.jpg',\n",
       " 'data/predict/happiness/happy_7.png',\n",
       " 'data/predict/fear/1636579058686.jpg',\n",
       " 'data/predict/sadness/sad_2.jpg',\n",
       " 'data/predict/sadness/sad1.jpeg',\n",
       " 'data/predict/sadness/sad_3.jpg',\n",
       " 'data/predict/sadness/1636579058667.jpg',\n",
       " 'data/predict/sadness/sad_4.jpg',\n",
       " 'data/predict/sadness/1636579058699.jpg',\n",
       " 'data/predict/sadness/sad_5.jpg']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22327b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pred_ = []\n",
    "for p in imgs_pred:\n",
    "    temp = Image.open(p)\n",
    "    save = temp.copy()\n",
    "    imgs_pred_.append(save)\n",
    "    temp.close()\n",
    "\n",
    "imgs_array_pred = []\n",
    "for f in imgs_pred_:\n",
    "    img = f.convert(\"RGB\").resize((HEIGHT, WIDTH))\n",
    "    imgs_array_pred.append(np.array(img))\n",
    "imgs_array_pred = np.array(imgs_array_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1beb9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(imgs_array_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0203ae77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4598990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1021964e-03, 8.7440317e-04, 9.7397953e-01, 1.0640242e-02,\n",
       "        3.1060001e-03, 4.1390292e-04, 4.8838877e-03],\n",
       "       [1.1344533e-02, 1.5153108e-03, 9.6891606e-01, 8.2021318e-03,\n",
       "        5.0080214e-03, 6.8873167e-04, 4.3251230e-03],\n",
       "       [2.8427225e-01, 2.6198642e-02, 7.9301288e-03, 1.3626334e-03,\n",
       "        6.7581040e-01, 4.1654296e-03, 2.6052361e-04],\n",
       "       [9.8083234e-01, 9.7697061e-03, 6.6696777e-04, 2.0539167e-04,\n",
       "        7.8163873e-03, 6.1591150e-04, 9.3230170e-05],\n",
       "       [1.0409561e-03, 9.5198286e-04, 7.9968839e-04, 3.5151860e-04,\n",
       "        9.9646723e-01, 1.2970861e-04, 2.5880281e-04]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddb2d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 0, 4, 0, 4, 0, 1, 0, 2, 2, 4, 3, 3, 4, 0, 3, 3, 2, 4, 4,\n",
       "       6, 3, 0, 3, 0, 2, 0, 4, 0, 1, 4, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax(axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f2183a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= y_dummies.columns\n",
    "cats = [x.replace(\"0_\",\"\") for x in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30eb031c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b07eefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise fear data/predict/surprise/1636579058672.jpg\n",
      "surprise fear data/predict/surprise/1636579058703.jpg\n",
      "surprise neutral data/predict/surprise/1636579058689.jpg\n",
      "anger anger data/predict/anger/1636579058658.jpg\n",
      "anger neutral data/predict/anger/1636579058692.jpg\n",
      "neutral anger data/predict/neutral/neutral_2.jpg\n",
      "neutral neutral data/predict/neutral/neutral_3.jpg\n",
      "neutral anger data/predict/neutral/1636579058676.jpg\n",
      "neutral disgust data/predict/neutral/neutral_0.jpg\n",
      "neutral anger data/predict/neutral/1636579058682.jpg\n",
      "neutral fear data/predict/neutral/1636579058712.jpg\n",
      "neutral fear data/predict/neutral/neutral_1.jpg\n",
      "neutral neutral data/predict/neutral/neutral_4.jpg\n",
      "happiness happiness data/predict/happiness/happy_6.png\n",
      "happiness happiness data/predict/happiness/happy_8.png\n",
      "happiness neutral data/predict/happiness/1636579058696.jpg\n",
      "happiness anger data/predict/happiness/happy_4.png\n",
      "happiness happiness data/predict/happiness/happy_10.png\n",
      "happiness happiness data/predict/happiness/happy_11.png\n",
      "happiness fear data/predict/happiness/1636579058663.jpg\n",
      "happiness neutral data/predict/happiness/1636579058717.jpg\n",
      "happiness neutral data/predict/happiness/happy_3.jpeg\n",
      "happiness surprise data/predict/happiness/happy_14.jpg\n",
      "happiness happiness data/predict/happiness/happy_9.png\n",
      "happiness anger data/predict/happiness/happy_2.jpg\n",
      "happiness happiness data/predict/happiness/happy_7.png\n",
      "fear anger data/predict/fear/1636579058686.jpg\n",
      "sadness fear data/predict/sadness/sad_2.jpg\n",
      "sadness anger data/predict/sadness/sad1.jpeg\n",
      "sadness neutral data/predict/sadness/sad_3.jpg\n",
      "sadness anger data/predict/sadness/1636579058667.jpg\n",
      "sadness disgust data/predict/sadness/sad_4.jpg\n",
      "sadness neutral data/predict/sadness/1636579058699.jpg\n",
      "sadness neutral data/predict/sadness/sad_5.jpg\n"
     ]
    }
   ],
   "source": [
    "states_model = []\n",
    "for i in range(len(prediction)):\n",
    "    states_model.append(cats[prediction[i].argmax()])\n",
    "    print(state_pred[i],cats[prediction[i].argmax()],imgs_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c166ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "839cc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f8a8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2647058823529412"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(state_pred,states_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33581e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
