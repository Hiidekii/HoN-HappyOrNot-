{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import face_recognition as fr\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9ac7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/all/train/\",\"data/all/test/\"] #[\"data/CK+/\",\"data/fer/train/\"]\n",
    "# data  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs = []\n",
    "state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355c9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "            state.extend([item for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6c9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50964, 50964)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state),len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d0c4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['data/all/train/surprise/Training_86715155.jpg',\n",
       "  'data/all/train/surprise/Training_63289181.jpg',\n",
       "  'data/all/train/surprise/Training_85075254.jpg',\n",
       "  'data/all/train/surprise/Training_2929493.jpg',\n",
       "  'data/all/train/surprise/Abdullah_Nasseef_0001.jpg'],\n",
       " ['surprise', 'surprise', 'surprise', 'surprise', 'surprise'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[:5],state[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e8c4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = []\n",
    "try:\n",
    "    imgs_ = []\n",
    "    for p in imgs:\n",
    "        temp = Image.open(p)\n",
    "        save = temp.copy()\n",
    "        imgs_.append(save)\n",
    "        temp.close()\n",
    "except:\n",
    "    errs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "639dba4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7808de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50964"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8835de",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = []\n",
    "HEIGHT, WIDTH =48,48\n",
    "for f in imgs_:\n",
    "    img = f.convert(\"L\").resize((HEIGHT, WIDTH))\n",
    "    imgs_array.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a9634d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = [el/255 for el in imgs_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe5cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = np.array(imgs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03259b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50964, 48, 48)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6383adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_array = imgs_array.reshape((50964,48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05d8ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['sadness', 'happiness', 'anger', 'disgust', 'neutral', 'surprise', 'fear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43bcc66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sadness', 'happiness', 'anger', 'disgust', 'neutral', 'surprise', 'fear']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82e371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b65e3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(state)\n",
    "y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "335e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array,y_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b5d459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD, Adamax\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9db01d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "751fe068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 15:21:40.654902: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2021-11-15 15:21:40.654939: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: oobonioo-X570-AORUS-ELITE\n",
      "2021-11-15 15:21:40.654947: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: oobonioo-X570-AORUS-ELITE\n",
      "2021-11-15 15:21:40.655062: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.91.3\n",
      "2021-11-15 15:21:40.655085: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.91.3\n",
      "2021-11-15 15:21:40.655091: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.91.3\n",
      "2021-11-15 15:21:40.655348: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Flatten())\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(imgs_array.shape[1:])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu', input_shape=(imgs_array.shape[1:])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed763968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 15:22:30.682121: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1075/1075 [==============================] - 99s 91ms/step - loss: 1.7416 - accuracy: 0.3398 - val_loss: 1.6291 - val_accuracy: 0.3761\n",
      "Epoch 2/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.5056 - accuracy: 0.4415 - val_loss: 1.4227 - val_accuracy: 0.4711\n",
      "Epoch 3/5000\n",
      "1075/1075 [==============================] - 13s 12ms/step - loss: 1.4465 - accuracy: 0.4663 - val_loss: 1.4282 - val_accuracy: 0.4698\n",
      "Epoch 4/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.4189 - accuracy: 0.4762 - val_loss: 1.4278 - val_accuracy: 0.4653\n",
      "Epoch 5/5000\n",
      "1075/1075 [==============================] - 11s 11ms/step - loss: 1.3995 - accuracy: 0.4827 - val_loss: 1.3463 - val_accuracy: 0.5025\n",
      "Epoch 6/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.3876 - accuracy: 0.4859 - val_loss: 1.3277 - val_accuracy: 0.5111\n",
      "Epoch 7/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.3636 - accuracy: 0.4969 - val_loss: 1.3216 - val_accuracy: 0.5061\n",
      "Epoch 8/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.3415 - accuracy: 0.5058 - val_loss: 1.3154 - val_accuracy: 0.5174\n",
      "Epoch 9/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.3299 - accuracy: 0.5063 - val_loss: 1.3053 - val_accuracy: 0.5059\n",
      "Epoch 10/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.3145 - accuracy: 0.5153 - val_loss: 1.2836 - val_accuracy: 0.5258\n",
      "Epoch 11/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.2997 - accuracy: 0.5217 - val_loss: 1.2289 - val_accuracy: 0.5399\n",
      "Epoch 12/5000\n",
      "1075/1075 [==============================] - 11s 11ms/step - loss: 1.2883 - accuracy: 0.5230 - val_loss: 1.2343 - val_accuracy: 0.5404\n",
      "Epoch 13/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.2701 - accuracy: 0.5271 - val_loss: 1.2266 - val_accuracy: 0.5443\n",
      "Epoch 14/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.2626 - accuracy: 0.5305 - val_loss: 1.2171 - val_accuracy: 0.5443\n",
      "Epoch 15/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.2572 - accuracy: 0.5332 - val_loss: 1.2379 - val_accuracy: 0.5464\n",
      "Epoch 16/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.2413 - accuracy: 0.5402 - val_loss: 1.2492 - val_accuracy: 0.5349\n",
      "Epoch 17/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.2312 - accuracy: 0.5413 - val_loss: 1.2025 - val_accuracy: 0.5480\n",
      "Epoch 18/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.2244 - accuracy: 0.5484 - val_loss: 1.1813 - val_accuracy: 0.5621\n",
      "Epoch 19/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.2119 - accuracy: 0.5508 - val_loss: 1.2053 - val_accuracy: 0.5451\n",
      "Epoch 20/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1961 - accuracy: 0.5571 - val_loss: 1.1757 - val_accuracy: 0.5616\n",
      "Epoch 21/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1941 - accuracy: 0.5609 - val_loss: 1.1928 - val_accuracy: 0.5574\n",
      "Epoch 22/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1848 - accuracy: 0.5631 - val_loss: 1.1868 - val_accuracy: 0.5713\n",
      "Epoch 23/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1735 - accuracy: 0.5686 - val_loss: 1.1590 - val_accuracy: 0.5721\n",
      "Epoch 24/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1656 - accuracy: 0.5696 - val_loss: 1.1474 - val_accuracy: 0.5747\n",
      "Epoch 25/5000\n",
      "1075/1075 [==============================] - 11s 11ms/step - loss: 1.1544 - accuracy: 0.5710 - val_loss: 1.1676 - val_accuracy: 0.5713\n",
      "Epoch 26/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1464 - accuracy: 0.5799 - val_loss: 1.1826 - val_accuracy: 0.5600\n",
      "Epoch 27/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1407 - accuracy: 0.5799 - val_loss: 1.1473 - val_accuracy: 0.5762\n",
      "Epoch 28/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1351 - accuracy: 0.5847 - val_loss: 1.1558 - val_accuracy: 0.5723\n",
      "Epoch 29/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1254 - accuracy: 0.5846 - val_loss: 1.1527 - val_accuracy: 0.5739\n",
      "Epoch 30/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1321 - accuracy: 0.5861 - val_loss: 1.1511 - val_accuracy: 0.5721\n",
      "Epoch 31/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1186 - accuracy: 0.5926 - val_loss: 1.1514 - val_accuracy: 0.5786\n",
      "Epoch 32/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.1120 - accuracy: 0.5926 - val_loss: 1.1408 - val_accuracy: 0.5854\n",
      "Epoch 33/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0998 - accuracy: 0.5965 - val_loss: 1.1313 - val_accuracy: 0.5862\n",
      "Epoch 34/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0971 - accuracy: 0.5985 - val_loss: 1.1963 - val_accuracy: 0.5553\n",
      "Epoch 35/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0879 - accuracy: 0.6028 - val_loss: 1.1621 - val_accuracy: 0.5836\n",
      "Epoch 36/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0874 - accuracy: 0.6006 - val_loss: 1.1110 - val_accuracy: 0.6008\n",
      "Epoch 37/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0752 - accuracy: 0.6067 - val_loss: 1.1470 - val_accuracy: 0.5859\n",
      "Epoch 38/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0746 - accuracy: 0.6045 - val_loss: 1.1627 - val_accuracy: 0.5794\n",
      "Epoch 39/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0734 - accuracy: 0.6056 - val_loss: 1.1695 - val_accuracy: 0.5815\n",
      "Epoch 40/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0676 - accuracy: 0.6072 - val_loss: 1.1096 - val_accuracy: 0.5930\n",
      "Epoch 41/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0598 - accuracy: 0.6131 - val_loss: 1.1319 - val_accuracy: 0.5951\n",
      "Epoch 42/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0521 - accuracy: 0.6129 - val_loss: 1.1243 - val_accuracy: 0.5938\n",
      "Epoch 43/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0450 - accuracy: 0.6150 - val_loss: 1.1498 - val_accuracy: 0.5854\n",
      "Epoch 44/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0456 - accuracy: 0.6172 - val_loss: 1.1162 - val_accuracy: 0.6003\n",
      "Epoch 45/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0328 - accuracy: 0.6212 - val_loss: 1.1149 - val_accuracy: 0.5909\n",
      "Epoch 46/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0267 - accuracy: 0.6245 - val_loss: 1.1072 - val_accuracy: 0.5964\n",
      "Epoch 47/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0268 - accuracy: 0.6235 - val_loss: 1.1228 - val_accuracy: 0.5875\n",
      "Epoch 48/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0256 - accuracy: 0.6260 - val_loss: 1.1166 - val_accuracy: 0.5940\n",
      "Epoch 49/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0179 - accuracy: 0.6290 - val_loss: 1.1116 - val_accuracy: 0.6001\n",
      "Epoch 50/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0122 - accuracy: 0.6276 - val_loss: 1.1513 - val_accuracy: 0.5935\n",
      "Epoch 51/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0089 - accuracy: 0.6319 - val_loss: 1.1140 - val_accuracy: 0.5987\n",
      "Epoch 52/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 1.0008 - accuracy: 0.6331 - val_loss: 1.1028 - val_accuracy: 0.6048\n",
      "Epoch 53/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9992 - accuracy: 0.6343 - val_loss: 1.1447 - val_accuracy: 0.5870\n",
      "Epoch 54/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9838 - accuracy: 0.6428 - val_loss: 1.1063 - val_accuracy: 0.6019\n",
      "Epoch 55/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9853 - accuracy: 0.6407 - val_loss: 1.1182 - val_accuracy: 0.5998\n",
      "Epoch 56/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9863 - accuracy: 0.6400 - val_loss: 1.1765 - val_accuracy: 0.5844\n",
      "Epoch 57/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9949 - accuracy: 0.6346 - val_loss: 1.1101 - val_accuracy: 0.6027\n",
      "Epoch 58/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9763 - accuracy: 0.6452 - val_loss: 1.0960 - val_accuracy: 0.6045\n",
      "Epoch 59/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9773 - accuracy: 0.6428 - val_loss: 1.1581 - val_accuracy: 0.5888\n",
      "Epoch 60/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9802 - accuracy: 0.6405 - val_loss: 1.1034 - val_accuracy: 0.6035\n",
      "Epoch 61/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9639 - accuracy: 0.6522 - val_loss: 1.1270 - val_accuracy: 0.6019\n",
      "Epoch 62/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9589 - accuracy: 0.6511 - val_loss: 1.1497 - val_accuracy: 0.5922\n",
      "Epoch 63/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9657 - accuracy: 0.6491 - val_loss: 1.0954 - val_accuracy: 0.6055\n",
      "Epoch 64/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9627 - accuracy: 0.6508 - val_loss: 1.1104 - val_accuracy: 0.6029\n",
      "Epoch 65/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9607 - accuracy: 0.6477 - val_loss: 1.1554 - val_accuracy: 0.5985\n",
      "Epoch 66/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9464 - accuracy: 0.6553 - val_loss: 1.1217 - val_accuracy: 0.6014\n",
      "Epoch 67/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9513 - accuracy: 0.6526 - val_loss: 1.0972 - val_accuracy: 0.5995\n",
      "Epoch 68/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9452 - accuracy: 0.6560 - val_loss: 1.1697 - val_accuracy: 0.5912\n",
      "Epoch 69/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9552 - accuracy: 0.6507 - val_loss: 1.1087 - val_accuracy: 0.6014\n",
      "Epoch 70/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9299 - accuracy: 0.6605 - val_loss: 1.1222 - val_accuracy: 0.5956\n",
      "Epoch 71/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9356 - accuracy: 0.6597 - val_loss: 1.1329 - val_accuracy: 0.6053\n",
      "Epoch 72/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9279 - accuracy: 0.6635 - val_loss: 1.1398 - val_accuracy: 0.6084\n",
      "Epoch 73/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9213 - accuracy: 0.6639 - val_loss: 1.1500 - val_accuracy: 0.6001\n",
      "Epoch 74/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9254 - accuracy: 0.6645 - val_loss: 1.1091 - val_accuracy: 0.6006\n",
      "Epoch 75/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9150 - accuracy: 0.6650 - val_loss: 1.1617 - val_accuracy: 0.5990\n",
      "Epoch 76/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9119 - accuracy: 0.6664 - val_loss: 1.1212 - val_accuracy: 0.6097\n",
      "Epoch 77/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9127 - accuracy: 0.6662 - val_loss: 1.1602 - val_accuracy: 0.5967\n",
      "Epoch 78/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9150 - accuracy: 0.6647 - val_loss: 1.1159 - val_accuracy: 0.6045\n",
      "Epoch 79/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9103 - accuracy: 0.6664 - val_loss: 1.1119 - val_accuracy: 0.6116\n",
      "Epoch 80/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9022 - accuracy: 0.6712 - val_loss: 1.1223 - val_accuracy: 0.6001\n",
      "Epoch 81/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8997 - accuracy: 0.6753 - val_loss: 1.1413 - val_accuracy: 0.5917\n",
      "Epoch 82/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.9031 - accuracy: 0.6682 - val_loss: 1.1157 - val_accuracy: 0.6061\n",
      "Epoch 83/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8952 - accuracy: 0.6751 - val_loss: 1.1283 - val_accuracy: 0.6024\n",
      "Epoch 84/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8913 - accuracy: 0.6753 - val_loss: 1.1109 - val_accuracy: 0.6082\n",
      "Epoch 85/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8960 - accuracy: 0.6713 - val_loss: 1.1203 - val_accuracy: 0.6087\n",
      "Epoch 86/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8926 - accuracy: 0.6757 - val_loss: 1.1031 - val_accuracy: 0.6129\n",
      "Epoch 87/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8922 - accuracy: 0.6751 - val_loss: 1.1237 - val_accuracy: 0.6042\n",
      "Epoch 88/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8868 - accuracy: 0.6778 - val_loss: 1.1390 - val_accuracy: 0.5943\n",
      "Epoch 89/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8797 - accuracy: 0.6824 - val_loss: 1.1144 - val_accuracy: 0.6123\n",
      "Epoch 90/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8762 - accuracy: 0.6778 - val_loss: 1.1397 - val_accuracy: 0.6095\n",
      "Epoch 91/5000\n",
      "1075/1075 [==============================] - 11s 11ms/step - loss: 0.8828 - accuracy: 0.6780 - val_loss: 1.1415 - val_accuracy: 0.6011\n",
      "Epoch 92/5000\n",
      "1075/1075 [==============================] - 11s 11ms/step - loss: 0.8788 - accuracy: 0.6822 - val_loss: 1.1252 - val_accuracy: 0.6110\n",
      "Epoch 93/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8715 - accuracy: 0.6824 - val_loss: 1.1678 - val_accuracy: 0.6003\n",
      "Epoch 94/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8802 - accuracy: 0.6782 - val_loss: 1.1157 - val_accuracy: 0.6113\n",
      "Epoch 95/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8680 - accuracy: 0.6835 - val_loss: 1.1311 - val_accuracy: 0.6037\n",
      "Epoch 96/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8667 - accuracy: 0.6839 - val_loss: 1.1249 - val_accuracy: 0.6082\n",
      "Epoch 97/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8667 - accuracy: 0.6831 - val_loss: 1.1179 - val_accuracy: 0.6076\n",
      "Epoch 98/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8533 - accuracy: 0.6876 - val_loss: 1.1411 - val_accuracy: 0.6095\n",
      "Epoch 99/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8599 - accuracy: 0.6849 - val_loss: 1.1410 - val_accuracy: 0.6123\n",
      "Epoch 100/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8563 - accuracy: 0.6906 - val_loss: 1.1533 - val_accuracy: 0.6040\n",
      "Epoch 101/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8533 - accuracy: 0.6861 - val_loss: 1.1586 - val_accuracy: 0.6076\n",
      "Epoch 102/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8551 - accuracy: 0.6840 - val_loss: 1.1292 - val_accuracy: 0.6129\n",
      "Epoch 103/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8459 - accuracy: 0.6912 - val_loss: 1.1440 - val_accuracy: 0.6123\n",
      "Epoch 104/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8477 - accuracy: 0.6924 - val_loss: 1.1341 - val_accuracy: 0.6144\n",
      "Epoch 105/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8447 - accuracy: 0.6938 - val_loss: 1.1587 - val_accuracy: 0.6100\n",
      "Epoch 106/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8451 - accuracy: 0.6935 - val_loss: 1.1303 - val_accuracy: 0.6199\n",
      "Epoch 107/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8427 - accuracy: 0.6931 - val_loss: 1.1793 - val_accuracy: 0.5980\n",
      "Epoch 108/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8417 - accuracy: 0.6925 - val_loss: 1.1319 - val_accuracy: 0.6063\n",
      "Epoch 109/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8337 - accuracy: 0.6994 - val_loss: 1.1392 - val_accuracy: 0.6147\n",
      "Epoch 110/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8387 - accuracy: 0.6958 - val_loss: 1.1326 - val_accuracy: 0.6181\n",
      "Epoch 111/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8342 - accuracy: 0.6983 - val_loss: 1.1324 - val_accuracy: 0.6074\n",
      "Epoch 112/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8315 - accuracy: 0.6986 - val_loss: 1.1403 - val_accuracy: 0.6121\n",
      "Epoch 113/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8268 - accuracy: 0.7005 - val_loss: 1.1400 - val_accuracy: 0.6100\n",
      "Epoch 114/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8286 - accuracy: 0.6979 - val_loss: 1.2963 - val_accuracy: 0.5650\n",
      "Epoch 115/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8343 - accuracy: 0.6977 - val_loss: 1.1450 - val_accuracy: 0.6037\n",
      "Epoch 116/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8248 - accuracy: 0.6993 - val_loss: 1.1509 - val_accuracy: 0.6116\n",
      "Epoch 117/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8214 - accuracy: 0.7023 - val_loss: 1.1472 - val_accuracy: 0.6021\n",
      "Epoch 118/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8195 - accuracy: 0.7020 - val_loss: 1.1498 - val_accuracy: 0.6137\n",
      "Epoch 119/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8166 - accuracy: 0.7042 - val_loss: 1.1311 - val_accuracy: 0.6147\n",
      "Epoch 120/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8151 - accuracy: 0.7047 - val_loss: 1.1518 - val_accuracy: 0.6063\n",
      "Epoch 121/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8128 - accuracy: 0.7038 - val_loss: 1.1286 - val_accuracy: 0.6050\n",
      "Epoch 122/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8160 - accuracy: 0.7008 - val_loss: 1.1494 - val_accuracy: 0.6074\n",
      "Epoch 123/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8124 - accuracy: 0.7052 - val_loss: 1.1809 - val_accuracy: 0.6103\n",
      "Epoch 124/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8094 - accuracy: 0.7054 - val_loss: 1.1508 - val_accuracy: 0.6108\n",
      "Epoch 125/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8118 - accuracy: 0.7069 - val_loss: 1.1596 - val_accuracy: 0.6121\n",
      "Epoch 126/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8012 - accuracy: 0.7066 - val_loss: 1.1414 - val_accuracy: 0.6142\n",
      "Epoch 127/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8025 - accuracy: 0.7106 - val_loss: 1.1408 - val_accuracy: 0.6173\n",
      "Epoch 128/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8055 - accuracy: 0.7056 - val_loss: 1.1724 - val_accuracy: 0.6037\n",
      "Epoch 129/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8052 - accuracy: 0.7095 - val_loss: 1.1843 - val_accuracy: 0.6001\n",
      "Epoch 130/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.8041 - accuracy: 0.7089 - val_loss: 1.1381 - val_accuracy: 0.6178\n",
      "Epoch 131/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.7959 - accuracy: 0.7088 - val_loss: 1.1825 - val_accuracy: 0.6100\n",
      "Epoch 132/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.7944 - accuracy: 0.7130 - val_loss: 1.1503 - val_accuracy: 0.6118\n",
      "Epoch 133/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.7959 - accuracy: 0.7131 - val_loss: 1.1581 - val_accuracy: 0.6121\n",
      "Epoch 134/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.7867 - accuracy: 0.7143 - val_loss: 1.1739 - val_accuracy: 0.6011\n",
      "Epoch 135/5000\n",
      "1075/1075 [==============================] - 11s 10ms/step - loss: 0.7948 - accuracy: 0.7110 - val_loss: 1.1659 - val_accuracy: 0.6055\n",
      "Epoch 136/5000\n",
      " 397/1075 [==========>...................] - ETA: 6s - loss: 0.7907 - accuracy: 0.7129"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25987/4152606848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras import callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "\n",
    "fecha=str(date.today().year)+str(date.today().month)+str(date.today().day)    \n",
    "symbol = 'alldata'\n",
    "h5 = symbol + '_1_' + fecha + '.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                       monitor='loss',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True,\n",
    "                                       #save_weights_only=True,\n",
    "                                       mode='auto',\n",
    "                                       save_freq=1)\n",
    "callback = [checkpoint]\n",
    "json = symbol + '_best_model' + fecha + '.json'\n",
    "model_json = model.to_json()\n",
    "with open(json, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "modelo = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 5000,callbacks = callback,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dbceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/predict/\"]\n",
    "# data_pred  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs_pred = []\n",
    "state_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b355f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs_pred.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "            state_pred.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31d91a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/predict/surprise/1636579058672.jpg',\n",
       " 'data/predict/surprise/1636579058703.jpg',\n",
       " 'data/predict/surprise/1636579058689.jpg',\n",
       " 'data/predict/anger/1636579058658.jpg',\n",
       " 'data/predict/anger/1636579058692.jpg',\n",
       " 'data/predict/neutral/neutral_2.jpg',\n",
       " 'data/predict/neutral/neutral_3.jpg',\n",
       " 'data/predict/neutral/1636579058676.jpg',\n",
       " 'data/predict/neutral/neutral_0.jpg',\n",
       " 'data/predict/neutral/1636579058682.jpg',\n",
       " 'data/predict/neutral/1636579058712.jpg',\n",
       " 'data/predict/neutral/neutral_1.jpg',\n",
       " 'data/predict/neutral/neutral_4.jpg',\n",
       " 'data/predict/happiness/happy_6.png',\n",
       " 'data/predict/happiness/happy_8.png',\n",
       " 'data/predict/happiness/1636579058696.jpg',\n",
       " 'data/predict/happiness/happy_4.png',\n",
       " 'data/predict/happiness/happy_10.png',\n",
       " 'data/predict/happiness/happy_11.png',\n",
       " 'data/predict/happiness/1636579058663.jpg',\n",
       " 'data/predict/happiness/1636579058717.jpg',\n",
       " 'data/predict/happiness/happy_3.jpeg',\n",
       " 'data/predict/happiness/happy_14.jpg',\n",
       " 'data/predict/happiness/happy_9.png',\n",
       " 'data/predict/happiness/happy_2.jpg',\n",
       " 'data/predict/happiness/happy_7.png',\n",
       " 'data/predict/fear/1636579058686.jpg',\n",
       " 'data/predict/sadness/sad_2.jpg',\n",
       " 'data/predict/sadness/sad1.jpeg',\n",
       " 'data/predict/sadness/sad_3.jpg',\n",
       " 'data/predict/sadness/1636579058667.jpg',\n",
       " 'data/predict/sadness/sad_4.jpg',\n",
       " 'data/predict/sadness/1636579058699.jpg',\n",
       " 'data/predict/sadness/sad_5.jpg']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22327b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pred_ = []\n",
    "for p in imgs_pred:\n",
    "    temp = Image.open(p)\n",
    "    save = temp.copy()\n",
    "    imgs_pred_.append(save)\n",
    "    temp.close()\n",
    "\n",
    "imgs_array_pred = []\n",
    "for f in imgs_pred_:\n",
    "    img = f.convert(\"L\").resize((HEIGHT, WIDTH))\n",
    "    imgs_array_pred.append(np.array(img))\n",
    "imgs_array_pred = np.array(imgs_array_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1beb9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(imgs_array_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0203ae77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4598990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 5.2877351e-30, 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [9.9999988e-01, 0.0000000e+00, 6.0679409e-17, 0.0000000e+00,\n",
       "        7.0373964e-08, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.2767212e-26, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.6539792e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        9.8346025e-01, 0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddb2d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax(axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f2183a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= y_dummies.columns\n",
    "cats = [x.replace(\"0_\",\"\") for x in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30eb031c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b07eefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise neutral data/predict/surprise/1636579058672.jpg\n",
      "surprise anger data/predict/surprise/1636579058703.jpg\n",
      "surprise neutral data/predict/surprise/1636579058689.jpg\n",
      "anger neutral data/predict/anger/1636579058658.jpg\n",
      "anger neutral data/predict/anger/1636579058692.jpg\n",
      "neutral neutral data/predict/neutral/neutral_2.jpg\n",
      "neutral neutral data/predict/neutral/neutral_3.jpg\n",
      "neutral fear data/predict/neutral/1636579058676.jpg\n",
      "neutral neutral data/predict/neutral/neutral_0.jpg\n",
      "neutral neutral data/predict/neutral/1636579058682.jpg\n",
      "neutral neutral data/predict/neutral/1636579058712.jpg\n",
      "neutral neutral data/predict/neutral/neutral_1.jpg\n",
      "neutral neutral data/predict/neutral/neutral_4.jpg\n",
      "happiness neutral data/predict/happiness/happy_6.png\n",
      "happiness neutral data/predict/happiness/happy_8.png\n",
      "happiness neutral data/predict/happiness/1636579058696.jpg\n",
      "happiness neutral data/predict/happiness/happy_4.png\n",
      "happiness neutral data/predict/happiness/happy_10.png\n",
      "happiness neutral data/predict/happiness/happy_11.png\n",
      "happiness neutral data/predict/happiness/1636579058663.jpg\n",
      "happiness anger data/predict/happiness/1636579058717.jpg\n",
      "happiness neutral data/predict/happiness/happy_3.jpeg\n",
      "happiness neutral data/predict/happiness/happy_14.jpg\n",
      "happiness neutral data/predict/happiness/happy_9.png\n",
      "happiness neutral data/predict/happiness/happy_2.jpg\n",
      "happiness neutral data/predict/happiness/happy_7.png\n",
      "fear neutral data/predict/fear/1636579058686.jpg\n",
      "sadness neutral data/predict/sadness/sad_2.jpg\n",
      "sadness neutral data/predict/sadness/sad1.jpeg\n",
      "sadness neutral data/predict/sadness/sad_3.jpg\n",
      "sadness neutral data/predict/sadness/1636579058667.jpg\n",
      "sadness neutral data/predict/sadness/sad_4.jpg\n",
      "sadness neutral data/predict/sadness/1636579058699.jpg\n",
      "sadness neutral data/predict/sadness/sad_5.jpg\n"
     ]
    }
   ],
   "source": [
    "states_model = []\n",
    "for i in range(len(prediction)):\n",
    "    states_model.append(cats[prediction[i].argmax()])\n",
    "    print(state_pred[i],cats[prediction[i].argmax()],imgs_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c166ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "839cc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f8a8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20588235294117646"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(state_pred,states_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33581e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
