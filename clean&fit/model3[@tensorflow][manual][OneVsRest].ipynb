{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import face_recognition as fr\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('gui_2/assets/haarcascade_frontalface_default.xml')\n",
    "HEIGHT, WIDTH =48,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9ac7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/all/train/\",\"data/all/test/\"] #[\"data/CK+/\",\"data/fer/train/\"]\n",
    "# data  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs = []\n",
    "state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "355c9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in paths:\n",
    "#     for item in listdir(path):\n",
    "#         if item not in ignore:\n",
    "#             imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "#             state.extend([item for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1a6c9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50964, 50964)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs),len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "313463ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats = ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']\n",
    "# dif_collections= []\n",
    "# for emotion in cats:\n",
    "#     dic = {\"x\":[],\"y\":[]}\n",
    "#     for i in range(len(state)):\n",
    "#         if state[i] == emotion:\n",
    "#             dic[\"x\"].append(imgs[i])\n",
    "#             dic[\"y\"].append(emotion)\n",
    "#     dif_collections.append(dic)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "14e5cd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5305, 5305)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dif_collections[0][\"x\"]),len(dif_collections[0][\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0c14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": item}for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32166a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ = []\n",
    "state = []\n",
    "for p in imgs:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.1, 5)\n",
    "    if len(faces)==1:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_.append(recortada)\n",
    "            state.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_ = [el/255 for el in imgs_]\n",
    "imgs_array = np.array(imgs_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbcb58bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22087, 48, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e892e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# errs = []\n",
    "# try:\n",
    "#     imgs_ = []\n",
    "#     for p in imgs:\n",
    "#         temp = Image.open(p)\n",
    "#         save = temp.copy()\n",
    "#         imgs_.append(save)\n",
    "#         temp.close()\n",
    "# except:\n",
    "#     errs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a50273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_array = []\n",
    "# HEIGHT, WIDTH =48,48\n",
    "# for f in imgs_:\n",
    "#     img = f.convert(\"L\").resize((HEIGHT, WIDTH))\n",
    "#     imgs_array.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f7f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_array = [el/255 for el in imgs_array]\n",
    "# imgs_array = np.array(imgs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad18b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array= imgs_array.reshape((len(imgs_array),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7808de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22087, 48, 48, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc84d548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b65e3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(state)\n",
    "y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f5764951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_anger</th>\n",
       "      <th>0_disgust</th>\n",
       "      <th>0_fear</th>\n",
       "      <th>0_happiness</th>\n",
       "      <th>0_neutral</th>\n",
       "      <th>0_sadness</th>\n",
       "      <th>0_surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22151</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22152 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0_anger  0_disgust  0_fear  0_happiness  0_neutral  0_sadness  \\\n",
       "0            0          0       0            0          0          0   \n",
       "1            0          0       0            0          0          0   \n",
       "2            0          0       0            0          0          0   \n",
       "3            0          0       0            0          0          0   \n",
       "4            0          0       0            0          0          0   \n",
       "...        ...        ...     ...          ...        ...        ...   \n",
       "22147        0          0       0            0          0          1   \n",
       "22148        0          0       0            0          0          1   \n",
       "22149        0          0       0            0          0          1   \n",
       "22150        0          0       0            0          0          1   \n",
       "22151        0          0       0            0          0          1   \n",
       "\n",
       "       0_surprise  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "22147           0  \n",
       "22148           0  \n",
       "22149           0  \n",
       "22150           0  \n",
       "22151           0  \n",
       "\n",
       "[22152 rows x 7 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "335e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array,y_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5d459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,BatchNormalization,Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD, Adamax\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db01d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751fe068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 10:12:55.495982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:55.500440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:55.500812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:55.501621: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-16 10:12:55.503007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:55.503351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:55.503682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:56.543518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:56.543907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:56.544233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 10:12:56.544577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5890 MB memory:  -> device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 1-conv\n",
    "model.add(Conv2D(64,(3,3),padding='same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2-conv\n",
    "model.add(Conv2D(128,(5,5),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ed763968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "468/468 [==============================] - 164s 349ms/step - loss: 1.3120 - accuracy: 0.5623 - val_loss: 1.7550 - val_accuracy: 0.5523\n",
      "Epoch 2/5000\n",
      "468/468 [==============================] - 7s 15ms/step - loss: 1.0201 - accuracy: 0.6705 - val_loss: 0.8999 - val_accuracy: 0.7034\n",
      "Epoch 3/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.8980 - accuracy: 0.7010 - val_loss: 0.9983 - val_accuracy: 0.6781\n",
      "Epoch 4/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.8206 - accuracy: 0.7225 - val_loss: 0.9735 - val_accuracy: 0.7136\n",
      "Epoch 5/5000\n",
      "468/468 [==============================] - 6s 13ms/step - loss: 0.7671 - accuracy: 0.7389 - val_loss: 0.8901 - val_accuracy: 0.7262\n",
      "Epoch 6/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.7236 - accuracy: 0.7483 - val_loss: 0.7286 - val_accuracy: 0.7635\n",
      "Epoch 7/5000\n",
      "468/468 [==============================] - 6s 13ms/step - loss: 0.6974 - accuracy: 0.7574 - val_loss: 0.7686 - val_accuracy: 0.7389\n",
      "Epoch 8/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.6607 - accuracy: 0.7692 - val_loss: 0.8412 - val_accuracy: 0.7076\n",
      "Epoch 9/5000\n",
      "468/468 [==============================] - 6s 13ms/step - loss: 0.6381 - accuracy: 0.7733 - val_loss: 0.7567 - val_accuracy: 0.7527\n",
      "Epoch 10/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.5963 - accuracy: 0.7902 - val_loss: 0.8282 - val_accuracy: 0.7539\n",
      "Epoch 11/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.5676 - accuracy: 0.7982 - val_loss: 0.6780 - val_accuracy: 0.7834\n",
      "Epoch 12/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.5508 - accuracy: 0.8020 - val_loss: 0.8169 - val_accuracy: 0.7677\n",
      "Epoch 13/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.5168 - accuracy: 0.8175 - val_loss: 0.8655 - val_accuracy: 0.7653\n",
      "Epoch 14/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.4784 - accuracy: 0.8256 - val_loss: 0.8127 - val_accuracy: 0.7473\n",
      "Epoch 15/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.4621 - accuracy: 0.8330 - val_loss: 0.7971 - val_accuracy: 0.7690\n",
      "Epoch 16/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.4357 - accuracy: 0.8427 - val_loss: 0.6472 - val_accuracy: 0.8002\n",
      "Epoch 17/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.4013 - accuracy: 0.8536 - val_loss: 0.7626 - val_accuracy: 0.7708\n",
      "Epoch 18/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.3863 - accuracy: 0.8589 - val_loss: 0.7677 - val_accuracy: 0.7708\n",
      "Epoch 19/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.3544 - accuracy: 0.8740 - val_loss: 1.1440 - val_accuracy: 0.7521\n",
      "Epoch 20/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.3250 - accuracy: 0.8832 - val_loss: 0.7164 - val_accuracy: 0.7864\n",
      "Epoch 21/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.3240 - accuracy: 0.8830 - val_loss: 0.9838 - val_accuracy: 0.7605\n",
      "Epoch 22/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2828 - accuracy: 0.8981 - val_loss: 0.9166 - val_accuracy: 0.7557\n",
      "Epoch 23/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.2715 - accuracy: 0.9025 - val_loss: 0.8929 - val_accuracy: 0.7882\n",
      "Epoch 24/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.2579 - accuracy: 0.9079 - val_loss: 0.9092 - val_accuracy: 0.7401\n",
      "Epoch 25/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2492 - accuracy: 0.9118 - val_loss: 1.2907 - val_accuracy: 0.7762\n",
      "Epoch 26/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2323 - accuracy: 0.9160 - val_loss: 0.8270 - val_accuracy: 0.7611\n",
      "Epoch 27/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.8867 - val_accuracy: 0.7744\n",
      "Epoch 28/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2012 - accuracy: 0.9270 - val_loss: 0.9955 - val_accuracy: 0.7503\n",
      "Epoch 29/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.2062 - accuracy: 0.9267 - val_loss: 0.8809 - val_accuracy: 0.7527\n",
      "Epoch 30/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.1845 - accuracy: 0.9367 - val_loss: 1.0327 - val_accuracy: 0.7593\n",
      "Epoch 31/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.1771 - accuracy: 0.9350 - val_loss: 1.0906 - val_accuracy: 0.7617\n",
      "Epoch 32/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1664 - accuracy: 0.9401 - val_loss: 0.9480 - val_accuracy: 0.7978\n",
      "Epoch 33/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.1634 - accuracy: 0.9422 - val_loss: 1.0691 - val_accuracy: 0.7647\n",
      "Epoch 34/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1583 - accuracy: 0.9453 - val_loss: 1.3893 - val_accuracy: 0.7647\n",
      "Epoch 35/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1505 - accuracy: 0.9468 - val_loss: 1.1880 - val_accuracy: 0.7906\n",
      "Epoch 36/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1413 - accuracy: 0.9492 - val_loss: 1.0650 - val_accuracy: 0.7876\n",
      "Epoch 37/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1363 - accuracy: 0.9489 - val_loss: 1.0134 - val_accuracy: 0.7413\n",
      "Epoch 38/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1301 - accuracy: 0.9537 - val_loss: 1.0262 - val_accuracy: 0.7756\n",
      "Epoch 39/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.1328 - accuracy: 0.9536 - val_loss: 1.2765 - val_accuracy: 0.7792\n",
      "Epoch 40/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1241 - accuracy: 0.9555 - val_loss: 1.1251 - val_accuracy: 0.7617\n",
      "Epoch 41/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.1181 - accuracy: 0.9585 - val_loss: 1.1753 - val_accuracy: 0.7587\n",
      "Epoch 42/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1152 - accuracy: 0.9592 - val_loss: 1.3238 - val_accuracy: 0.7702\n",
      "Epoch 43/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1200 - accuracy: 0.9599 - val_loss: 1.3789 - val_accuracy: 0.7744\n",
      "Epoch 44/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1073 - accuracy: 0.9621 - val_loss: 1.0442 - val_accuracy: 0.7822\n",
      "Epoch 45/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1066 - accuracy: 0.9626 - val_loss: 1.1233 - val_accuracy: 0.7720\n",
      "Epoch 46/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1056 - accuracy: 0.9631 - val_loss: 1.0811 - val_accuracy: 0.7485\n",
      "Epoch 47/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0959 - accuracy: 0.9644 - val_loss: 1.7126 - val_accuracy: 0.7503\n",
      "Epoch 48/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0983 - accuracy: 0.9635 - val_loss: 1.1705 - val_accuracy: 0.7587\n",
      "Epoch 49/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.0882 - accuracy: 0.9698 - val_loss: 1.0804 - val_accuracy: 0.7762\n",
      "Epoch 50/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0861 - accuracy: 0.9698 - val_loss: 1.4472 - val_accuracy: 0.7738\n",
      "Epoch 51/5000\n",
      "287/468 [=================>............] - ETA: 2s - loss: 0.0845 - accuracy: 0.9704"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9892/3435792529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras import callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "\n",
    "fecha=str(date.today().year)+str(date.today().month)+str(date.today().day)    \n",
    "symbol = 'alldata'\n",
    "h5 = symbol + '_2_' + fecha + '_v4.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                       monitor='loss',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True,\n",
    "                                       #save_weights_only=True,\n",
    "                                       mode='auto',\n",
    "                                       save_freq=1)\n",
    "callback = [checkpoint]\n",
    "json = symbol + '_best_model' + fecha + '.json'\n",
    "model_json = model.to_json()\n",
    "with open(json, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "modelo = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 5000,callbacks = callback,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dbceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/predict/\"]\n",
    "# data_pred  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs_pred = []\n",
    "state_pred = []\n",
    "im_pred = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b355f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs_pred.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": item}for p in listdir(f\"{path}{item}\")])\n",
    "            #state_pred.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31d91a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22f61c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "777cc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/alldata_2_20211115.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e98ad3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22327b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pred_ = []\n",
    "state_pred = []\n",
    "for p in imgs_pred:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.1, 5)\n",
    "    if len(faces)>0:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_pred_.append(recortada)\n",
    "            state_pred.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_pred_ = [el/255 for el in imgs_pred_]\n",
    "imgs_pred_ = np.array(imgs_pred_)\n",
    "imgs_pred_= imgs_pred_.reshape((len(imgs_pred_),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ad51f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac6f59d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1beb9214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 11:18:41.023004: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-16 11:18:41.576788: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2021-11-16 11:18:41.970375: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0203ae77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4598990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.4894957e-05, 3.7728207e-09, 6.8917363e-03, 2.5523326e-08,\n",
       "        5.1553252e-07, 1.6033631e-07, 9.9302262e-01],\n",
       "       [1.0018654e-08, 1.5192790e-12, 1.0942463e-05, 9.6037495e-01,\n",
       "        4.1263547e-07, 5.1037152e-12, 3.9613694e-02],\n",
       "       [4.5495493e-05, 5.8931235e-08, 2.1744058e-02, 4.6597645e-01,\n",
       "        1.6718764e-02, 2.0592222e-04, 4.9530926e-01],\n",
       "       [2.2900608e-08, 2.4792980e-12, 1.6108788e-07, 6.3151351e-10,\n",
       "        8.7809113e-08, 4.0679465e-12, 9.9999964e-01],\n",
       "       [1.9551955e-07, 1.1681860e-10, 8.5411684e-06, 9.5126493e-09,\n",
       "        2.8508299e-07, 1.5838350e-11, 9.9999106e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddb2d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 0, 6, 4, 0, 1, 3, 0, 5, 4, 1,\n",
       "       1, 1, 1, 4, 1, 4, 2, 4, 1, 1, 4, 0, 0, 0, 0, 0, 4, 0, 4, 4, 4, 4,\n",
       "       3, 4, 5, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 0, 1, 0,\n",
       "       1, 0, 4, 2, 6, 6, 6, 4, 5, 5, 4, 5, 5, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax(axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f2183a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_dummies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23374/3596858499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcats\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_dummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0_\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_dummies' is not defined"
     ]
    }
   ],
   "source": [
    "cats= y_dummies.columns\n",
    "cats = [x.replace(\"0_\",\"\") for x in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30eb031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07d087b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b07eefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise surprise\n",
      "surprise happiness\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise neutral\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise anger\n",
      "surprise surprise\n",
      "disgust neutral\n",
      "disgust anger\n",
      "disgust disgust\n",
      "disgust happiness\n",
      "disgust anger\n",
      "disgust sadness\n",
      "disgust neutral\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust neutral\n",
      "disgust disgust\n",
      "disgust neutral\n",
      "disgust fear\n",
      "disgust neutral\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust neutral\n",
      "anger anger\n",
      "anger anger\n",
      "anger anger\n",
      "anger anger\n",
      "anger anger\n",
      "anger neutral\n",
      "anger anger\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral happiness\n",
      "neutral neutral\n",
      "neutral sadness\n",
      "neutral happiness\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "fear surprise\n",
      "fear anger\n",
      "fear disgust\n",
      "fear anger\n",
      "fear disgust\n",
      "fear anger\n",
      "fear neutral\n",
      "fear fear\n",
      "fear surprise\n",
      "fear surprise\n",
      "fear surprise\n",
      "sadness neutral\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness neutral\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness neutral\n"
     ]
    }
   ],
   "source": [
    "states_model = []\n",
    "i=0\n",
    "for i in range(len(prediction)):\n",
    "    states_model.append(cats[prediction[i].argmax()])\n",
    "    print(state_pred[i],cats[prediction[i].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "839cc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f8a8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6125"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(state_pred,states_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33581e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35ed4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(states_model, state_pred)\n",
    "labels = ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d567e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pd.DataFrame(conf,columns=labels, index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1b0722e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "heatmap = sns.heatmap(conf, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34457c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ff76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d721b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
