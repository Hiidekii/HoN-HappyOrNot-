{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import face_recognition as fr\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from os import remove\n",
    "import operations\n",
    "import operations_cutting\n",
    "face_cascade = cv2.CascadeClassifier('gui_2/assets/haarcascade_frontalface_default.xml')\n",
    "HEIGHT, WIDTH =48,48\n",
    "other_emotions =  [ 'fear', 'disgust','anger']\n",
    "initial_emotions = ['sadness','happiness', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ac7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"../data/all/train/\",\"../data/all/test/\"]#[\"data/CK_cut/\"]#[\"data/all/train/\",\"data/all/test/\"]# #[\"data/CK+/\",\"data/fer/train/\"]\n",
    "# data  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb9095",
   "metadata": {},
   "source": [
    "### With operations module we can load all images in the paths provided. We can load in a single objet data for train only 1 model or in 2 combined models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data object with all images in paths.\n",
    "dataset= operations.Datos(paths,initial_emotions,48,48)\n",
    "#Load image's directions\n",
    "dataset.imgs_load_initial()\n",
    "dataset.imgs_load_other()\n",
    "\n",
    "#Load images in a array\n",
    "dataset.image_to_data()\n",
    "dataset.image_to_data('other')\n",
    "#Convert the images in gray and dimensions provided\n",
    "dataset.data_conversion()\n",
    "dataset.data_conversion('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed51cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.other_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b8bfe",
   "metadata": {},
   "source": [
    "## With operations_cutting we can load images cutted with cv2.cascadeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9baad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cut = operations_cutting.Data_cut(paths,initial_emotions,48,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ab43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cut.load_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bed20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cut.recortar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cut.imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_cut.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b221d9",
   "metadata": {},
   "source": [
    "# Preparamos entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(dataset.state)\n",
    "y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5764951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.imgs,y_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,BatchNormalization,Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19d26d",
   "metadata": {},
   "source": [
    "# MODELO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751fe068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 1-conv\n",
    "model.add(Conv2D(64,(3,3),padding='same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2-conv\n",
    "model.add(Conv2D(128,(5,5),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(len(set(state)),activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8cea2",
   "metadata": {},
   "source": [
    "# MODELO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Flatten())\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(imgs_array.shape[1:])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu', input_shape=(imgs_array.shape[1:])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(set(state), activation='softmax'))\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86542935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 200\n",
    "# # steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "# # validation_steps = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "# checkpoint = ModelCheckpoint(\"modelo_ck_fc_tfeid_p1.h5\",monitor='val_accuracy',\n",
    "#                             save_weights_only=False,save_best_only=True, model='max',verbose=1)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=3,min_lr=0.000001,model='auto')\n",
    "\n",
    "# callbacks = [PlotLossesCallback(),checkpoint,reduce_lr]\n",
    "# history = model.fit(X_train,y_train,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=(X_test,y_test),\n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed763968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras import callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "\n",
    "fecha=str(date.today().year)+str(date.today().month)+str(date.today().day)    \n",
    "symbol = 'no_dig_no_fear'\n",
    "h5 = symbol + fecha + '_v1.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                       monitor='loss',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True,\n",
    "                                       #save_weights_only=True,\n",
    "                                       mode='auto',\n",
    "                                       save_freq=1)\n",
    "callback = [checkpoint]\n",
    "\n",
    "modelo = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 5000,callbacks = callback,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b3eda",
   "metadata": {},
   "source": [
    "## Operaciones para comprobar predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/predict/\"]\n",
    "# data_pred  = listdir(path)\n",
    "imgs_pred = []\n",
    "state_pred = []\n",
    "im_pred = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            if item in initial_emotions:\n",
    "                imgs_pred.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": get_emotion(item,True)}for p in listdir(f\"{path}{item}\")])\n",
    "                #state_pred.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d91a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f61c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777cc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('intial_emotions_2_20211116_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22327b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pred_ = []\n",
    "state_pred = []\n",
    "for p in imgs_pred:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.05, 5)\n",
    "    if len(faces)>0:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_pred_.append(recortada)\n",
    "            state_pred.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_pred_ = [el/255 for el in imgs_pred_]\n",
    "imgs_pred_ = np.array(imgs_pred_)\n",
    "imgs_pred_= imgs_pred_.reshape((len(imgs_pred_),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad51f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(state_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203ae77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4598990",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.argmax(axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2183a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= y_dummies.columns\n",
    "cats = [x.replace(\"0_\",\"\") for x in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d087b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07eefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_model = []\n",
    "i=0\n",
    "for i in range(len(prediction)):\n",
    "    states_model.append(cats[prediction[i].argmax()])\n",
    "    print(state_pred[i],cats[prediction[i].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(state_pred,states_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33581e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(states_model, state_pred)\n",
    "conf = pd.DataFrame(conf,columns=cats, index=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "heatmap = sns.heatmap(conf, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec979b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5734112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
