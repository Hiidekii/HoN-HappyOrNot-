{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9db5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import face_recognition as fr\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('gui_2/assets/haarcascade_frontalface_default.xml')\n",
    "HEIGHT, WIDTH =48,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6a9ac7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/all/train/\",\"data/all/test/\"] #[\"data/CK+/\",\"data/fer/train/\"]\n",
    "# data  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs = []\n",
    "state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "355c9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs.extend([f\"{path}{item}/{p}\" for p in listdir(f\"{path}{item}\")])\n",
    "            state.extend([item for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1a6c9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50964"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ad0c14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": item}for p in listdir(f\"{path}{item}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "32166a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ = []\n",
    "state = []\n",
    "for p in imgs:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.1, 5)\n",
    "    if len(faces)==1:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_.append(recortada)\n",
    "            state.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_ = [el/255 for el in imgs_]\n",
    "imgs_array = np.array(imgs_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cbcb58bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22152, 48, 48)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e892e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = []\n",
    "try:\n",
    "    imgs_ = []\n",
    "    for p in imgs:\n",
    "        temp = Image.open(p)\n",
    "        save = temp.copy()\n",
    "        imgs_.append(save)\n",
    "        temp.close()\n",
    "except:\n",
    "    errs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a50273",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = []\n",
    "HEIGHT, WIDTH =48,48\n",
    "for f in imgs_:\n",
    "    img = f.convert(\"L\").resize((HEIGHT, WIDTH))\n",
    "    imgs_array.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = [el/255 for el in imgs_array]\n",
    "imgs_array = np.array(imgs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3ad18b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array= imgs_array.reshape((len(imgs_array),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c7808de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22152, 48, 48, 1)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fc84d548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " ...]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "05d8ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['sadness', 'happiness', 'anger', 'disgust', 'neutral', 'surprise', 'fear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "43bcc66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sadness', 'happiness', 'anger', 'disgust', 'neutral', 'surprise', 'fear']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82e371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b65e3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(state)\n",
    "y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f5764951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_anger</th>\n",
       "      <th>0_disgust</th>\n",
       "      <th>0_fear</th>\n",
       "      <th>0_happiness</th>\n",
       "      <th>0_neutral</th>\n",
       "      <th>0_sadness</th>\n",
       "      <th>0_surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22151</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22152 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0_anger  0_disgust  0_fear  0_happiness  0_neutral  0_sadness  \\\n",
       "0            0          0       0            0          0          0   \n",
       "1            0          0       0            0          0          0   \n",
       "2            0          0       0            0          0          0   \n",
       "3            0          0       0            0          0          0   \n",
       "4            0          0       0            0          0          0   \n",
       "...        ...        ...     ...          ...        ...        ...   \n",
       "22147        0          0       0            0          0          1   \n",
       "22148        0          0       0            0          0          1   \n",
       "22149        0          0       0            0          0          1   \n",
       "22150        0          0       0            0          0          1   \n",
       "22151        0          0       0            0          0          1   \n",
       "\n",
       "       0_surprise  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "22147           0  \n",
       "22148           0  \n",
       "22149           0  \n",
       "22150           0  \n",
       "22151           0  \n",
       "\n",
       "[22152 rows x 7 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "335e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array,y_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2b5d459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,BatchNormalization,Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD, Adamax\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9db01d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "751fe068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 1-conv\n",
    "model.add(Conv2D(64,(3,3),padding='same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2-conv\n",
    "model.add(Conv2D(128,(5,5),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4-conv\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ed763968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "468/468 [==============================] - 164s 349ms/step - loss: 1.3120 - accuracy: 0.5623 - val_loss: 1.7550 - val_accuracy: 0.5523\n",
      "Epoch 2/5000\n",
      "468/468 [==============================] - 7s 15ms/step - loss: 1.0201 - accuracy: 0.6705 - val_loss: 0.8999 - val_accuracy: 0.7034\n",
      "Epoch 3/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.8980 - accuracy: 0.7010 - val_loss: 0.9983 - val_accuracy: 0.6781\n",
      "Epoch 4/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.8206 - accuracy: 0.7225 - val_loss: 0.9735 - val_accuracy: 0.7136\n",
      "Epoch 5/5000\n",
      "468/468 [==============================] - 6s 13ms/step - loss: 0.7671 - accuracy: 0.7389 - val_loss: 0.8901 - val_accuracy: 0.7262\n",
      "Epoch 6/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.7236 - accuracy: 0.7483 - val_loss: 0.7286 - val_accuracy: 0.7635\n",
      "Epoch 7/5000\n",
      "468/468 [==============================] - 6s 13ms/step - loss: 0.6974 - accuracy: 0.7574 - val_loss: 0.7686 - val_accuracy: 0.7389\n",
      "Epoch 8/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.6607 - accuracy: 0.7692 - val_loss: 0.8412 - val_accuracy: 0.7076\n",
      "Epoch 9/5000\n",
      "468/468 [==============================] - 6s 13ms/step - loss: 0.6381 - accuracy: 0.7733 - val_loss: 0.7567 - val_accuracy: 0.7527\n",
      "Epoch 10/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.5963 - accuracy: 0.7902 - val_loss: 0.8282 - val_accuracy: 0.7539\n",
      "Epoch 11/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.5676 - accuracy: 0.7982 - val_loss: 0.6780 - val_accuracy: 0.7834\n",
      "Epoch 12/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.5508 - accuracy: 0.8020 - val_loss: 0.8169 - val_accuracy: 0.7677\n",
      "Epoch 13/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.5168 - accuracy: 0.8175 - val_loss: 0.8655 - val_accuracy: 0.7653\n",
      "Epoch 14/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.4784 - accuracy: 0.8256 - val_loss: 0.8127 - val_accuracy: 0.7473\n",
      "Epoch 15/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.4621 - accuracy: 0.8330 - val_loss: 0.7971 - val_accuracy: 0.7690\n",
      "Epoch 16/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.4357 - accuracy: 0.8427 - val_loss: 0.6472 - val_accuracy: 0.8002\n",
      "Epoch 17/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.4013 - accuracy: 0.8536 - val_loss: 0.7626 - val_accuracy: 0.7708\n",
      "Epoch 18/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.3863 - accuracy: 0.8589 - val_loss: 0.7677 - val_accuracy: 0.7708\n",
      "Epoch 19/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.3544 - accuracy: 0.8740 - val_loss: 1.1440 - val_accuracy: 0.7521\n",
      "Epoch 20/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.3250 - accuracy: 0.8832 - val_loss: 0.7164 - val_accuracy: 0.7864\n",
      "Epoch 21/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.3240 - accuracy: 0.8830 - val_loss: 0.9838 - val_accuracy: 0.7605\n",
      "Epoch 22/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2828 - accuracy: 0.8981 - val_loss: 0.9166 - val_accuracy: 0.7557\n",
      "Epoch 23/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.2715 - accuracy: 0.9025 - val_loss: 0.8929 - val_accuracy: 0.7882\n",
      "Epoch 24/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.2579 - accuracy: 0.9079 - val_loss: 0.9092 - val_accuracy: 0.7401\n",
      "Epoch 25/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2492 - accuracy: 0.9118 - val_loss: 1.2907 - val_accuracy: 0.7762\n",
      "Epoch 26/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2323 - accuracy: 0.9160 - val_loss: 0.8270 - val_accuracy: 0.7611\n",
      "Epoch 27/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.8867 - val_accuracy: 0.7744\n",
      "Epoch 28/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.2012 - accuracy: 0.9270 - val_loss: 0.9955 - val_accuracy: 0.7503\n",
      "Epoch 29/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.2062 - accuracy: 0.9267 - val_loss: 0.8809 - val_accuracy: 0.7527\n",
      "Epoch 30/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.1845 - accuracy: 0.9367 - val_loss: 1.0327 - val_accuracy: 0.7593\n",
      "Epoch 31/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.1771 - accuracy: 0.9350 - val_loss: 1.0906 - val_accuracy: 0.7617\n",
      "Epoch 32/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1664 - accuracy: 0.9401 - val_loss: 0.9480 - val_accuracy: 0.7978\n",
      "Epoch 33/5000\n",
      "468/468 [==============================] - 6s 12ms/step - loss: 0.1634 - accuracy: 0.9422 - val_loss: 1.0691 - val_accuracy: 0.7647\n",
      "Epoch 34/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1583 - accuracy: 0.9453 - val_loss: 1.3893 - val_accuracy: 0.7647\n",
      "Epoch 35/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1505 - accuracy: 0.9468 - val_loss: 1.1880 - val_accuracy: 0.7906\n",
      "Epoch 36/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1413 - accuracy: 0.9492 - val_loss: 1.0650 - val_accuracy: 0.7876\n",
      "Epoch 37/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1363 - accuracy: 0.9489 - val_loss: 1.0134 - val_accuracy: 0.7413\n",
      "Epoch 38/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1301 - accuracy: 0.9537 - val_loss: 1.0262 - val_accuracy: 0.7756\n",
      "Epoch 39/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.1328 - accuracy: 0.9536 - val_loss: 1.2765 - val_accuracy: 0.7792\n",
      "Epoch 40/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1241 - accuracy: 0.9555 - val_loss: 1.1251 - val_accuracy: 0.7617\n",
      "Epoch 41/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.1181 - accuracy: 0.9585 - val_loss: 1.1753 - val_accuracy: 0.7587\n",
      "Epoch 42/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1152 - accuracy: 0.9592 - val_loss: 1.3238 - val_accuracy: 0.7702\n",
      "Epoch 43/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1200 - accuracy: 0.9599 - val_loss: 1.3789 - val_accuracy: 0.7744\n",
      "Epoch 44/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1073 - accuracy: 0.9621 - val_loss: 1.0442 - val_accuracy: 0.7822\n",
      "Epoch 45/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1066 - accuracy: 0.9626 - val_loss: 1.1233 - val_accuracy: 0.7720\n",
      "Epoch 46/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.1056 - accuracy: 0.9631 - val_loss: 1.0811 - val_accuracy: 0.7485\n",
      "Epoch 47/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0959 - accuracy: 0.9644 - val_loss: 1.7126 - val_accuracy: 0.7503\n",
      "Epoch 48/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0983 - accuracy: 0.9635 - val_loss: 1.1705 - val_accuracy: 0.7587\n",
      "Epoch 49/5000\n",
      "468/468 [==============================] - 5s 12ms/step - loss: 0.0882 - accuracy: 0.9698 - val_loss: 1.0804 - val_accuracy: 0.7762\n",
      "Epoch 50/5000\n",
      "468/468 [==============================] - 5s 11ms/step - loss: 0.0861 - accuracy: 0.9698 - val_loss: 1.4472 - val_accuracy: 0.7738\n",
      "Epoch 51/5000\n",
      "287/468 [=================>............] - ETA: 2s - loss: 0.0845 - accuracy: 0.9704"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9892/3435792529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/core/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras import callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "\n",
    "fecha=str(date.today().year)+str(date.today().month)+str(date.today().day)    \n",
    "symbol = 'alldata'\n",
    "h5 = symbol + '_2_' + fecha + '_v3.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                       monitor='loss',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True,\n",
    "                                       #save_weights_only=True,\n",
    "                                       mode='auto',\n",
    "                                       save_freq=1)\n",
    "callback = [checkpoint]\n",
    "json = symbol + '_best_model' + fecha + '.json'\n",
    "model_json = model.to_json()\n",
    "with open(json, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "modelo = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 5000,callbacks = callback,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5dbceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/predict/\"]\n",
    "# data_pred  = listdir(path)\n",
    "ignore = [\"morralla\",\".DS_Store\",\"contempt\"]\n",
    "imgs_pred = []\n",
    "state_pred = []\n",
    "im_pred = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "b355f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    for item in listdir(path):\n",
    "        if item not in ignore:\n",
    "            imgs_pred.extend([{\"path\": f\"{path}{item}/{p}\", \"emotion\": item}for p in listdir(f\"{path}{item}\")])\n",
    "            #state_pred.extend([item for p in listdir(f\"{path}{item}\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "31d91a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "777cc70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e98ad3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "22327b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pred_ = []\n",
    "state_pred = []\n",
    "for p in imgs_pred:\n",
    "    temp = cv2.imread(p[\"path\"],0)\n",
    "    faces = face_cascade.detectMultiScale(temp, 1.1, 5)\n",
    "    if len(faces)>0:\n",
    "        for (x,y,w,h) in faces:\n",
    "            recortada = temp[y:y+h, x:x+w]\n",
    "            recortada = cv2.resize(recortada,(HEIGHT, WIDTH))\n",
    "            imgs_pred_.append(recortada)\n",
    "            state_pred.append(p[\"emotion\"])\n",
    "    \n",
    "        \n",
    "imgs_pred_ = [el/255 for el in imgs_pred_]\n",
    "imgs_pred_ = np.array(imgs_pred_)\n",
    "imgs_pred_= imgs_pred_.reshape((len(imgs_pred_),48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5ad51f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ac6f59d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1beb9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(imgs_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "0203ae77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e4598990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0618264e-11, 8.9035246e-12, 5.8411742e-06, 2.6749628e-06,\n",
       "        4.5739416e-06, 6.9660222e-11, 9.9998701e-01],\n",
       "       [4.0105770e-06, 8.8373922e-09, 4.1971711e-05, 1.3365221e-03,\n",
       "        2.6611859e-05, 1.1816149e-09, 9.9859077e-01],\n",
       "       [3.9991625e-11, 2.0976216e-11, 5.4403685e-04, 6.8589667e-05,\n",
       "        5.8596584e-06, 6.5326516e-12, 9.9938154e-01],\n",
       "       [2.4197083e-10, 3.5122205e-12, 8.1186624e-07, 6.7610136e-12,\n",
       "        4.5277952e-06, 8.9603276e-11, 9.9999464e-01],\n",
       "       [6.3670960e-08, 3.6881996e-08, 5.6235513e-05, 2.5642853e-06,\n",
       "        1.8189395e-03, 5.6610801e-08, 9.9812204e-01]], dtype=float32)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ddb2d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 1, 1, 1, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 4, 4, 1, 0, 0, 0, 0, 4, 4, 4, 4,\n",
       "       6, 4, 4, 2, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 2, 6, 6, 2,\n",
       "       6, 6, 2, 2, 2, 4, 6, 5, 5, 4, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax(axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2f2183a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= y_dummies.columns\n",
    "cats = [x.replace(\"0_\",\"\") for x in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "30eb031c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "07d087b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b07eefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise fear\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "surprise surprise\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust happiness\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust happiness\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust neutral\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "disgust disgust\n",
      "anger neutral\n",
      "anger neutral\n",
      "anger disgust\n",
      "anger anger\n",
      "anger anger\n",
      "anger anger\n",
      "anger anger\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral surprise\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral fear\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness happiness\n",
      "happiness neutral\n",
      "happiness happiness\n",
      "fear fear\n",
      "fear surprise\n",
      "fear surprise\n",
      "fear fear\n",
      "fear surprise\n",
      "fear surprise\n",
      "fear fear\n",
      "fear fear\n",
      "fear fear\n",
      "fear neutral\n",
      "fear surprise\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness neutral\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n",
      "sadness sadness\n"
     ]
    }
   ],
   "source": [
    "states_model = []\n",
    "i=0\n",
    "for i in range(len(prediction)):\n",
    "    states_model.append(cats[prediction[i].argmax()])\n",
    "    print(state_pred[i],cats[prediction[i].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "839cc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5f8a8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(state_pred,states_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33581e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
